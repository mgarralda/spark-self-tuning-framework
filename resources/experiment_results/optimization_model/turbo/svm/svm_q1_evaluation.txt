Target workload: id='application_1753112283118_0437_svm_large' time_stamp=datetime.datetime(2025, 9, 30, 12, 22, 5, 990243) app_name='SVM with Params(100,1.0,0.01,hdfs://172.18.0.20:9000/HiBench/SVM/Input/large,MEMORY_ONLY)' app_benchmark_workload='svm' time_execution=2020 dataset_size=4013178096260.0 app_benchmark_data_size=<InputDataSizeType.LARGE: 'large'> environment=Environment(driver_cores=1, driver_memory_gb=2, dynamic_allocation=False, executor_cores=5, executor_instances=3, executor_memory_gb=3, sql_adaptive=False, sql_shuffle_partitions=200, task_cpus=1) time_resources=None vector_metrics_yoro=[38444.362085914814, 883.0, 805566.0, 168783.89980209994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8869253103495576, 0.0, 255.0, 8.052608702638851, 0.5053611028554446, 0.0, 136.0, 4.382938594996994, 65603.86817859673, 0.0, 12814992.0, 595947.3616389172, 0.0, 0.0, 0.0, 0.0, 65324.47486340047, 0.0, 9611244.0, 422305.88583454565, 2.7460734779726117, 0.0, 801.0, 35.03602582458729, 91748659.06723669, 0.0, 144010911.0, 44654531.36373677, 2.367435586749274, 0.0, 1830.0, 20.5983197556201, 1906324.263277017, 424800.0, 653892600.0, 7359114.335876835, 610.0187924373014, 0.0, 11954.0, 631.8629129796302, 336807781.0955396, 347600.0, 1627650400.0, 176892480.33583447, 73.81212135067786, 0.0, 11067.0, 483.3809034349173, 0.0326924395875723, 0.0, 139.0, 0.877072303514219, 0.43741569694337123, 0.0, 142.0, 4.075381174915614] vector_metrics_garralda=[0.17522917066310897, 0.5732991452395171, 0.155092070055617, 0.06574958268938834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07228129085249697, -1.0098204941898117, 0.9648391838471837, 0.008611316243076069, 0.07249557451207199, -1.0112069877735153, 0.9607941546092333, 0.008922378531755008, -1.7484983525419702, 1.0543815090347284, 0.6175206104825947, 0.10501171540424734, 0.0, 0.0, 0.0, 0.0, -1.5887185621355964, 0.9898190174925301, 0.6095149097811504, 0.10741197633623462, 0.044961139345578785, -1.025794678716364, 0.9932506939081438, 0.004584435453380944, -1.6388163621888607, 0.9321512504678565, 0.6494756696925067, 0.10268232540143188, 0.1389628782662683, -1.10219037019325, 0.9926720373381562, 0.013408121651896006, -0.08178628164807882, 0.001413005621976629, 0.5753464086207696, 0.09965546614276898, -0.1441871037889432, 0.8440422183284433, 0.1515708692098414, 0.06632651169097631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.8120284947429111, -0.22375025282055014, 0.9889446451995539, 0.029801830112556965, -1.5559476147202935, 1.0030328700007232, 0.5462682273523731, 0.11065977602800123, -1.3477594250101885, 1.3513434269981455, 0.26063086102813926, 0.13045960072320878, -1.5559476147202935, 1.0030328700007232, 0.5462682273523731, 0.11065977602800123, -1.932043105435729, 1.9808394457430265, 0.2470533008372015, 0.10264561717823051, 0.08473460485452482, -0.06437681770278098, 0.46682543014995187, 0.18049841578666342, -1.5773822082040954, 0.7389704030695131, 0.7203509666095957, 0.08235457596486802, -2.041194832484438, 1.214693816922734, 0.6245878441001256, 0.10407577122850739, 0.12301576379370215, 0.7819332851544685, 0.054093703373807756, 0.03035497812611543, -0.32707235383753464, 0.7154180463094952, 0.4441503119829657, 0.10667553128303871] resource_usage=None resource_shape=None
[Candidate Space] grid_size=10080, n_candidates=256 (n=2)
[Candidate Space]  Generated 256 candidates via Sobol.
[MetaLearning] Trained RF (WEIGHTED). Best params: {'regressor__rf__max_depth': 10, 'regressor__rf__max_features': 'sqrt', 'regressor__rf__n_estimators': 50}
[MetaLearning] Weight stats: {'weights_min': 1e-06, 'weights_max': 0.9999999999592717, 'weights_mean': 0.1484041776073614}
[MetaLearning] Saved WEIGHTED model to meta_rf_model.joblib
[TurBO] Step 1 | -EI=-59.978 | mu_pred(T)=26.26 | cfg=[  1   3   2   3   3 100   1]
[TurBO][CAS] f_pred=75.24 vs f_th=2020.00 -> RUN
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: turbo_bo_baseline, config: driver_cores=1 driver_memory=3 executor_cores=2 executor_instances=3 executor_memory=3 sql_shuffle_partitions=100 task_cpus=1
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/svm/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
patching args=
start SVM bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.SVMWithSGDExample           --master yarn --num-executors 3 --executor-cores 2 --executor-memory 3g --driver-memory 3g --driver-cores 1 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --numIterations 100 --storageLevel MEMORY_ONLY --stepSize 1.0 --regParam 0.01 hdfs://172.30.0.20:9000/HiBench/SVM/Input/large
25/09/30 12:23:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/09/30 12:23:02 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/09/30 12:23:03 INFO Configuration: resource-types.xml not found
25/09/30 12:23:03 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/09/30 12:23:03 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/09/30 12:23:03 INFO Client: Will allocate AM container, with 3456 MB memory including 384 MB overhead
25/09/30 12:23:03 INFO Client: Setting up container launch context for our AM
25/09/30 12:23:03 INFO Client: Setting up the launch environment for our AM container
25/09/30 12:23:03 INFO Client: Preparing resources for our AM container
25/09/30 12:23:04 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/09/30 12:23:05 INFO Client: Uploading resource file:/tmp/spark-88f8775f-7314-4f2a-b1a2-be107368ddc1/__spark_libs__7535677055198981691.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0045/__spark_libs__7535677055198981691.zip
25/09/30 12:23:06 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0045/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/09/30 12:23:09 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0045/sparkbench.conf
25/09/30 12:23:10 INFO Client: Uploading resource file:/tmp/spark-88f8775f-7314-4f2a-b1a2-be107368ddc1/__spark_conf__8937136094148392782.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0045/__spark_conf__.zip
25/09/30 12:23:10 INFO SecurityManager: Changing view acls to: sparker
25/09/30 12:23:10 INFO SecurityManager: Changing modify acls to: sparker
25/09/30 12:23:10 INFO SecurityManager: Changing view acls groups to:
25/09/30 12:23:10 INFO SecurityManager: Changing modify acls groups to:
25/09/30 12:23:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/09/30 12:23:10 INFO Client: Submitting application application_1759095470586_0045 to ResourceManager
25/09/30 12:23:10 INFO YarnClientImpl: Submitted application application_1759095470586_0045

=================================================================
Detected application_1759095470586_0045
=================================================================

25/09/30 12:23:11 INFO Client: Application report for application_1759095470586_0045 (state: ACCEPTED)
25/09/30 12:23:11 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1759234990619
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0045/
	 user: sparker
25/09/30 12:23:12 INFO Client: Application report for application_1759095470586_0045 (state: ACCEPTED)
25/09/30 12:23:13 INFO Client: Application report for application_1759095470586_0045 (state: ACCEPTED)
25/09/30 12:23:14 INFO Client: Application report for application_1759095470586_0045 (state: ACCEPTED)
25/09/30 12:23:15 INFO Client: Application report for application_1759095470586_0045 (state: ACCEPTED)
25/09/30 12:23:16 INFO Client: Application report for application_1759095470586_0045 (state: ACCEPTED)
25/09/30 12:23:17 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-2
	 ApplicationMaster RPC port: 35959
	 queue: default
	 start time: 1759234990619
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0045/
	 user: sparker
25/09/30 13:08:38 INFO Client: Application report for application_1759095470586_0045 (state: FINISHED)
25/09/30 13:08:38 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-2
	 ApplicationMaster RPC port: 35959
	 queue: default
	 start time: 1759234990619
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0045/
	 user: sparker
25/09/30 13:08:39 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1759095470586_0045 with large data and queued
=================================================================

25/09/30 13:08:39 INFO ShutdownHookManager: Deleting directory /tmp/spark-667cc379-dc9e-4de3-aca0-e1f2336aa7b3
25/09/30 13:08:39 INFO ShutdownHookManager: Deleting directory /tmp/spark-88f8775f-7314-4f2a-b1a2-be107368ddc1
/home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1759095470586_0045
Failed to download Spark logs, we'll retry in next iteration 1: 500 Server Error: Server Error for url: http://localhost:18080/api/v1/applications/application_1759095470586_0045/logs
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1759095470586_0045.zip
====================================================================================================
Benchmark Name: svm
Time to create app instrumentation: 0.03 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.06 seconds
Time to create stages instrumentation: 0.50 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 19.47 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
22.317219
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
22.472350
====================================================================================================
SQL PLANS: 0 | JOBS: 107 | JOBS WITHOUT SQL PLAN: 107 | STAGES: 210 | STAGES SKIPPED: 1 | TASK: 32865 TASK_WITH_ERRORS: 0 |
Get distributions elapsed_time: 0.035967 seconds
Starting parallel processing.
Time taken for parallel processing: 0.043869733810424805 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
22.505747
====================================================================================================
Finished application vectorization for application_1759095470586_0045_svm_large
Saving optimized workload into MongoDB: {'_id': 'application_1759095470586_0045_svm_large', 'experiment_id': 'svm_q1_evaluation', 'experiment_iteration': 1, 'target_workload': {'id': 'application_1753112283118_0437_svm_large', 'execution_time': 2020, 'name': 'svm', 'input_data_size': 'large', 'configuration': {'driver_cores': 1, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 5, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 200, 'task_cpus': 1}}, 'objective_function_real': 2721.999999999999, 'acquisition_function_score': -59.97777495194637, 'resource_usage_value': 21.0, 'execution_time': 2722, 'configuration': {'driver_cores': 1, 'driver_memory': 3, 'executor_cores': 2, 'executor_instances': 3, 'executor_memory': 3, 'sql_shuffle_partitions': 100, 'task_cpus': 1}, 'execution_time_error': 2696, 'objective_function_predict': 26.0, 'beta': None, 'alpha': None, 'repeated_config': True, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1759095470586_0045_svm_large documents into MongoDB
[TurBO] Step 2 | -EI=-105.149 | mu_pred(T)=100.36 | cfg=[  2   3   4   2   4 100   1]
[TurBO][CAS] f_pred=42.50 vs f_th=2722.00 -> RUN
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: turbo_bo_baseline, config: driver_cores=2 driver_memory=3 executor_cores=4 executor_instances=2 executor_memory=4 sql_shuffle_partitions=100 task_cpus=1
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/svm/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
patching args=
start SVM bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.SVMWithSGDExample           --master yarn --num-executors 2 --executor-cores 4 --executor-memory 4g --driver-memory 3g --driver-cores 2 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --numIterations 100 --storageLevel MEMORY_ONLY --stepSize 1.0 --regParam 0.01 hdfs://172.30.0.20:9000/HiBench/SVM/Input/large
25/09/30 13:09:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/09/30 13:09:47 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/09/30 13:09:48 INFO Configuration: resource-types.xml not found
25/09/30 13:09:48 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/09/30 13:09:48 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/09/30 13:09:48 INFO Client: Will allocate AM container, with 3456 MB memory including 384 MB overhead
25/09/30 13:09:48 INFO Client: Setting up container launch context for our AM
25/09/30 13:09:48 INFO Client: Setting up the launch environment for our AM container
25/09/30 13:09:48 INFO Client: Preparing resources for our AM container
25/09/30 13:09:48 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/09/30 13:09:49 INFO Client: Uploading resource file:/tmp/spark-32069d23-9021-49f0-8a2f-257e2736a4cc/__spark_libs__7827784474954846260.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0046/__spark_libs__7827784474954846260.zip
25/09/30 13:09:50 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0046/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/09/30 13:09:53 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0046/sparkbench.conf
25/09/30 13:09:54 INFO Client: Uploading resource file:/tmp/spark-32069d23-9021-49f0-8a2f-257e2736a4cc/__spark_conf__479807743036296489.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0046/__spark_conf__.zip
25/09/30 13:09:54 INFO SecurityManager: Changing view acls to: sparker
25/09/30 13:09:54 INFO SecurityManager: Changing modify acls to: sparker
25/09/30 13:09:54 INFO SecurityManager: Changing view acls groups to:
25/09/30 13:09:54 INFO SecurityManager: Changing modify acls groups to:
25/09/30 13:09:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/09/30 13:09:54 INFO Client: Submitting application application_1759095470586_0046 to ResourceManager
25/09/30 13:09:54 INFO YarnClientImpl: Submitted application application_1759095470586_0046

=================================================================
Detected application_1759095470586_0046
=================================================================

25/09/30 13:09:55 INFO Client: Application report for application_1759095470586_0046 (state: ACCEPTED)
25/09/30 13:09:55 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1759237794309
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0046/
	 user: sparker
25/09/30 13:09:56 INFO Client: Application report for application_1759095470586_0046 (state: ACCEPTED)
25/09/30 13:09:57 INFO Client: Application report for application_1759095470586_0046 (state: ACCEPTED)
25/09/30 13:09:58 INFO Client: Application report for application_1759095470586_0046 (state: ACCEPTED)
25/09/30 13:09:59 INFO Client: Application report for application_1759095470586_0046 (state: ACCEPTED)
25/09/30 13:10:00 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-2
	 ApplicationMaster RPC port: 43225
	 queue: default
	 start time: 1759237794309
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0046/
	 user: sparker
25/09/30 13:55:50 INFO Client: Application report for application_1759095470586_0046 (state: FINISHED)
25/09/30 13:55:50 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-2
	 ApplicationMaster RPC port: 43225
	 queue: default
	 start time: 1759237794309
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0046/
	 user: sparker
25/09/30 13:55:51 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1759095470586_0046 with large data and queued
=================================================================

25/09/30 13:55:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-32069d23-9021-49f0-8a2f-257e2736a4cc
25/09/30 13:55:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-381a26bd-c83d-4424-a056-5d323aa32490
/home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1759095470586_0046
Failed to download Spark logs, we'll retry in next iteration 1: 500 Server Error: Server Error for url: http://localhost:18080/api/v1/applications/application_1759095470586_0046/logs
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1759095470586_0046.zip
====================================================================================================
Benchmark Name: svm
Time to create app instrumentation: 0.06 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.10 seconds
Time to create stages instrumentation: 1.17 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 47.92 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
55.804942
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
56.188936
====================================================================================================
SQL PLANS: 0 | JOBS: 107 | JOBS WITHOUT SQL PLAN: 107 | STAGES: 210 | STAGES SKIPPED: 1 | TASK: 32881 TASK_WITH_ERRORS: 0 |
Get distributions elapsed_time: 0.077049 seconds
Starting parallel processing.
Time taken for parallel processing: 0.07942652702331543 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
56.145511
====================================================================================================
Finished application vectorization for application_1759095470586_0046_svm_large
Saving optimized workload into MongoDB: {'_id': 'application_1759095470586_0046_svm_large', 'experiment_id': 'svm_q1_evaluation', 'experiment_iteration': 2, 'target_workload': {'id': 'application_1753112283118_0437_svm_large', 'execution_time': 2020, 'name': 'svm', 'input_data_size': 'large', 'configuration': {'driver_cores': 1, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 5, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 200, 'task_cpus': 1}}, 'objective_function_real': 2750.0000000000005, 'acquisition_function_score': -105.1489687377481, 'resource_usage_value': 38.0, 'execution_time': 2750, 'configuration': {'driver_cores': 2, 'driver_memory': 3, 'executor_cores': 4, 'executor_instances': 2, 'executor_memory': 4, 'sql_shuffle_partitions': 100, 'task_cpus': 1}, 'execution_time_error': 2650, 'objective_function_predict': 100.00000000000003, 'beta': None, 'alpha': None, 'repeated_config': True, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1759095470586_0046_svm_large documents into MongoDB
[TurBO] Step 3 | -EI=-108.606 | mu_pred(T)=319.44 | cfg=[  2   3   3   2   4 150   2]
[TurBO][CAS] f_pred=299.75 vs f_th=2736.00 -> RUN
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: turbo_bo_baseline, config: driver_cores=2 driver_memory=3 executor_cores=3 executor_instances=2 executor_memory=4 sql_shuffle_partitions=150 task_cpus=2
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/svm/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
patching args=
start SVM bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.SVMWithSGDExample           --master yarn --num-executors 2 --executor-cores 3 --executor-memory 4g --driver-memory 3g --driver-cores 2 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --numIterations 100 --storageLevel MEMORY_ONLY --stepSize 1.0 --regParam 0.01 hdfs://172.30.0.20:9000/HiBench/SVM/Input/large
25/09/30 13:57:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/09/30 13:57:34 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/09/30 13:57:35 INFO Configuration: resource-types.xml not found
25/09/30 13:57:35 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/09/30 13:57:35 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/09/30 13:57:35 INFO Client: Will allocate AM container, with 3456 MB memory including 384 MB overhead
25/09/30 13:57:35 INFO Client: Setting up container launch context for our AM
25/09/30 13:57:35 INFO Client: Setting up the launch environment for our AM container
25/09/30 13:57:35 INFO Client: Preparing resources for our AM container
25/09/30 13:57:35 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/09/30 13:57:36 INFO Client: Uploading resource file:/tmp/spark-dd6e023c-cb9c-43ed-b6c2-5dd671d6d674/__spark_libs__4766954383645719144.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0047/__spark_libs__4766954383645719144.zip
25/09/30 13:57:38 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0047/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/09/30 13:57:41 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0047/sparkbench.conf
25/09/30 13:57:41 INFO Client: Uploading resource file:/tmp/spark-dd6e023c-cb9c-43ed-b6c2-5dd671d6d674/__spark_conf__2990438442740558585.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0047/__spark_conf__.zip
25/09/30 13:57:42 INFO SecurityManager: Changing view acls to: sparker
25/09/30 13:57:42 INFO SecurityManager: Changing modify acls to: sparker
25/09/30 13:57:42 INFO SecurityManager: Changing view acls groups to:
25/09/30 13:57:42 INFO SecurityManager: Changing modify acls groups to:
25/09/30 13:57:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/09/30 13:57:42 INFO Client: Submitting application application_1759095470586_0047 to ResourceManager
25/09/30 13:57:42 INFO YarnClientImpl: Submitted application application_1759095470586_0047

=================================================================
Detected application_1759095470586_0047
=================================================================

25/09/30 13:57:43 INFO Client: Application report for application_1759095470586_0047 (state: ACCEPTED)
25/09/30 13:57:43 INFO Client:
	 client token: N/A
	 diagnostics: [Tue Sep 30 13:57:43 +0000 2025] Scheduler has assigned a container for AM, waiting for AM container to be launched
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1759240662393
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0047/
	 user: sparker
25/09/30 13:57:44 INFO Client: Application report for application_1759095470586_0047 (state: ACCEPTED)
25/09/30 13:57:45 INFO Client: Application report for application_1759095470586_0047 (state: ACCEPTED)
25/09/30 13:57:46 INFO Client: Application report for application_1759095470586_0047 (state: ACCEPTED)
25/09/30 13:57:47 INFO Client: Application report for application_1759095470586_0047 (state: ACCEPTED)
25/09/30 13:57:48 INFO Client: Application report for application_1759095470586_0047 (state: ACCEPTED)
25/09/30 13:57:49 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-1
	 ApplicationMaster RPC port: 36963
	 queue: default
	 start time: 1759240662393
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0047/
	 user: sparker
25/09/30 15:41:23 INFO Client: Application report for application_1759095470586_0047 (state: FINISHED)
25/09/30 15:41:23 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-1
	 ApplicationMaster RPC port: 36963
	 queue: default
	 start time: 1759240662393
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0047/
	 user: sparker
25/09/30 15:41:24 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1759095470586_0047 with large data and queued
=================================================================

25/09/30 15:41:24 INFO ShutdownHookManager: Deleting directory /tmp/spark-dd6e023c-cb9c-43ed-b6c2-5dd671d6d674
25/09/30 15:41:24 INFO ShutdownHookManager: Deleting directory /tmp/spark-fb592084-f69c-40b8-bc76-53bc93f254fa
/home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1759095470586_0047
Failed to download Spark logs, we'll retry in next iteration 1: 500 Server Error: Server Error for url: http://localhost:18080/api/v1/applications/application_1759095470586_0047/logs
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1759095470586_0047.zip
====================================================================================================
Benchmark Name: svm
Time to create app instrumentation: 0.10 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.16 seconds
Time to create stages instrumentation: 1.66 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 54.72 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
69.641947
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
70.147223
====================================================================================================
SQL PLANS: 0 | JOBS: 107 | JOBS WITHOUT SQL PLAN: 107 | STAGES: 210 | STAGES SKIPPED: 1 | TASK: 32865 TASK_WITH_ERRORS: 0 |
Get distributions elapsed_time: 0.346948 seconds
Starting parallel processing.
Time taken for parallel processing: 0.14415621757507324 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
70.468075
====================================================================================================
Finished application vectorization for application_1759095470586_0047_svm_large
Saving optimized workload into MongoDB: {'_id': 'application_1759095470586_0047_svm_large', 'experiment_id': 'svm_q1_evaluation', 'experiment_iteration': 3, 'target_workload': {'id': 'application_1753112283118_0437_svm_large', 'execution_time': 2020, 'name': 'svm', 'input_data_size': 'large', 'configuration': {'driver_cores': 1, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 5, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 200, 'task_cpus': 1}}, 'objective_function_real': 6214.999999999995, 'acquisition_function_score': -108.60565208810743, 'resource_usage_value': 30.0, 'execution_time': 6215, 'configuration': {'driver_cores': 2, 'driver_memory': 3, 'executor_cores': 3, 'executor_instances': 2, 'executor_memory': 4, 'sql_shuffle_partitions': 150, 'task_cpus': 2}, 'execution_time_error': 5896, 'objective_function_predict': 318.99999999999994, 'beta': None, 'alpha': None, 'repeated_config': True, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1759095470586_0047_svm_large documents into MongoDB
[TurBO] Step 4 | -EI=-285.414 | mu_pred(T)=316.27 | cfg=[  1   3   1   3   4 300   1]
[TurBO][CAS] f_pred=77.02 vs f_th=3895.67 -> RUN
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: turbo_bo_baseline, config: driver_cores=1 driver_memory=3 executor_cores=1 executor_instances=3 executor_memory=4 sql_shuffle_partitions=300 task_cpus=1
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/svm/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
patching args=
start SVM bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.SVMWithSGDExample           --master yarn --num-executors 3 --executor-cores 1 --executor-memory 4g --driver-memory 3g --driver-cores 1 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --numIterations 100 --storageLevel MEMORY_ONLY --stepSize 1.0 --regParam 0.01 hdfs://172.30.0.20:9000/HiBench/SVM/Input/large
25/09/30 15:43:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/09/30 15:43:42 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/09/30 15:43:44 INFO Configuration: resource-types.xml not found
25/09/30 15:43:44 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/09/30 15:43:44 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/09/30 15:43:44 INFO Client: Will allocate AM container, with 3456 MB memory including 384 MB overhead
25/09/30 15:43:44 INFO Client: Setting up container launch context for our AM
25/09/30 15:43:44 INFO Client: Setting up the launch environment for our AM container
25/09/30 15:43:44 INFO Client: Preparing resources for our AM container
25/09/30 15:43:44 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/09/30 15:43:46 INFO Client: Uploading resource file:/tmp/spark-c4b6bf48-161c-4ba5-82a2-3e8bcc44c6f0/__spark_libs__6768302912146862851.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0048/__spark_libs__6768302912146862851.zip
25/09/30 15:43:48 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0048/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/09/30 15:43:51 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0048/sparkbench.conf
25/09/30 15:43:52 INFO Client: Uploading resource file:/tmp/spark-c4b6bf48-161c-4ba5-82a2-3e8bcc44c6f0/__spark_conf__4825606669797159076.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0048/__spark_conf__.zip
25/09/30 15:43:52 INFO SecurityManager: Changing view acls to: sparker
25/09/30 15:43:52 INFO SecurityManager: Changing modify acls to: sparker
25/09/30 15:43:52 INFO SecurityManager: Changing view acls groups to:
25/09/30 15:43:52 INFO SecurityManager: Changing modify acls groups to:
25/09/30 15:43:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/09/30 15:43:52 INFO Client: Submitting application application_1759095470586_0048 to ResourceManager
25/09/30 15:43:52 INFO YarnClientImpl: Submitted application application_1759095470586_0048

=================================================================
Detected application_1759095470586_0048
=================================================================

25/09/30 15:43:53 INFO Client: Application report for application_1759095470586_0048 (state: ACCEPTED)
25/09/30 15:43:53 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1759247032363
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0048/
	 user: sparker
25/09/30 15:43:54 INFO Client: Application report for application_1759095470586_0048 (state: ACCEPTED)
25/09/30 15:43:55 INFO Client: Application report for application_1759095470586_0048 (state: ACCEPTED)
25/09/30 15:43:56 INFO Client: Application report for application_1759095470586_0048 (state: ACCEPTED)
25/09/30 15:43:57 INFO Client: Application report for application_1759095470586_0048 (state: ACCEPTED)
25/09/30 15:43:58 INFO Client: Application report for application_1759095470586_0048 (state: ACCEPTED)
25/09/30 15:43:59 INFO Client: Application report for application_1759095470586_0048 (state: ACCEPTED)
25/09/30 15:44:00 INFO Client: Application report for application_1759095470586_0048 (state: ACCEPTED)
25/09/30 15:44:01 INFO Client: Application report for application_1759095470586_0048 (state: ACCEPTED)
25/09/30 15:44:02 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-2
	 ApplicationMaster RPC port: 43579
	 queue: default
	 start time: 1759247032363
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0048/
	 user: sparker
25/09/30 16:55:08 INFO Client: Application report for application_1759095470586_0048 (state: FINISHED)
25/09/30 16:55:09 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-2
	 ApplicationMaster RPC port: 43579
	 queue: default
	 start time: 1759247032363
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0048/
	 user: sparker
25/09/30 16:55:09 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1759095470586_0048 with large data and queued
=================================================================

25/09/30 16:55:09 INFO ShutdownHookManager: Deleting directory /tmp/spark-c4b6bf48-161c-4ba5-82a2-3e8bcc44c6f0
25/09/30 16:55:09 INFO ShutdownHookManager: Deleting directory /tmp/spark-2ab9e9eb-ba8e-43a1-9f1d-3bc4edd77129
/home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1759095470586_0048
Failed to download Spark logs, we'll retry in next iteration 1: 500 Server Error: Server Error for url: http://localhost:18080/api/v1/applications/application_1759095470586_0048/logs
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1759095470586_0048.zip
====================================================================================================
Benchmark Name: svm
Time to create app instrumentation: 0.07 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.17 seconds
Time to create stages instrumentation: 1.29 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 52.94 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
63.836742
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
64.222709
====================================================================================================
SQL PLANS: 0 | JOBS: 107 | JOBS WITHOUT SQL PLAN: 107 | STAGES: 210 | STAGES SKIPPED: 1 | TASK: 32841 TASK_WITH_ERRORS: 0 |
Get distributions elapsed_time: 0.176022 seconds
Starting parallel processing.
Time taken for parallel processing: 0.12067437171936035 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
64.369203
====================================================================================================
Finished application vectorization for application_1759095470586_0048_svm_large
Saving optimized workload into MongoDB: {'_id': 'application_1759095470586_0048_svm_large', 'experiment_id': 'svm_q1_evaluation', 'experiment_iteration': 4, 'target_workload': {'id': 'application_1753112283118_0437_svm_large', 'execution_time': 2020, 'name': 'svm', 'input_data_size': 'large', 'configuration': {'driver_cores': 1, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 5, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 200, 'task_cpus': 1}}, 'objective_function_real': 4269.000000000002, 'acquisition_function_score': -285.41410247585446, 'resource_usage_value': 15.0, 'execution_time': 4269, 'configuration': {'driver_cores': 1, 'driver_memory': 3, 'executor_cores': 1, 'executor_instances': 3, 'executor_memory': 4, 'sql_shuffle_partitions': 300, 'task_cpus': 1}, 'execution_time_error': 3953, 'objective_function_predict': 315.9999999999999, 'beta': None, 'alpha': None, 'repeated_config': True, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1759095470586_0048_svm_large documents into MongoDB
[TurBO] Step 5 | -EI=-330.878 | mu_pred(T)=342.06 | cfg=[  2   3   2   2   4 150   1]
[TurBO][CAS] f_pred=40.24 vs f_th=3989.00 -> RUN
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: turbo_bo_baseline, config: driver_cores=2 driver_memory=3 executor_cores=2 executor_instances=2 executor_memory=4 sql_shuffle_partitions=150 task_cpus=1
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/svm/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
patching args=
start SVM bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.SVMWithSGDExample           --master yarn --num-executors 2 --executor-cores 2 --executor-memory 4g --driver-memory 3g --driver-cores 2 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --numIterations 100 --storageLevel MEMORY_ONLY --stepSize 1.0 --regParam 0.01 hdfs://172.30.0.20:9000/HiBench/SVM/Input/large
25/09/30 16:57:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/09/30 16:57:09 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/09/30 16:57:10 INFO Configuration: resource-types.xml not found
25/09/30 16:57:10 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/09/30 16:57:10 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/09/30 16:57:10 INFO Client: Will allocate AM container, with 3456 MB memory including 384 MB overhead
25/09/30 16:57:10 INFO Client: Setting up container launch context for our AM
25/09/30 16:57:10 INFO Client: Setting up the launch environment for our AM container
25/09/30 16:57:10 INFO Client: Preparing resources for our AM container
25/09/30 16:57:10 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/09/30 16:57:11 INFO Client: Uploading resource file:/tmp/spark-19abe336-7e4f-4359-876c-4689af2b5ce7/__spark_libs__6092477540779729256.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0049/__spark_libs__6092477540779729256.zip
25/09/30 16:57:12 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0049/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/09/30 16:57:15 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0049/sparkbench.conf
25/09/30 16:57:16 INFO Client: Uploading resource file:/tmp/spark-19abe336-7e4f-4359-876c-4689af2b5ce7/__spark_conf__8646600648851004416.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0049/__spark_conf__.zip
25/09/30 16:57:16 INFO SecurityManager: Changing view acls to: sparker
25/09/30 16:57:16 INFO SecurityManager: Changing modify acls to: sparker
25/09/30 16:57:16 INFO SecurityManager: Changing view acls groups to:
25/09/30 16:57:16 INFO SecurityManager: Changing modify acls groups to:
25/09/30 16:57:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/09/30 16:57:16 INFO Client: Submitting application application_1759095470586_0049 to ResourceManager
25/09/30 16:57:16 INFO YarnClientImpl: Submitted application application_1759095470586_0049

=================================================================
Detected application_1759095470586_0049
=================================================================

25/09/30 16:57:17 INFO Client: Application report for application_1759095470586_0049 (state: ACCEPTED)
25/09/30 16:57:17 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1759251436224
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0049/
	 user: sparker
25/09/30 16:57:18 INFO Client: Application report for application_1759095470586_0049 (state: ACCEPTED)
25/09/30 16:57:19 INFO Client: Application report for application_1759095470586_0049 (state: ACCEPTED)
25/09/30 16:57:20 INFO Client: Application report for application_1759095470586_0049 (state: ACCEPTED)
25/09/30 16:57:21 INFO Client: Application report for application_1759095470586_0049 (state: ACCEPTED)
25/09/30 16:57:22 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-2
	 ApplicationMaster RPC port: 38883
	 queue: default
	 start time: 1759251436224
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0049/
	 user: sparker
25/09/30 17:54:20 INFO Client: Application report for application_1759095470586_0049 (state: FINISHED)
25/09/30 17:54:21 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-2
	 ApplicationMaster RPC port: 38883
	 queue: default
	 start time: 1759251436224
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0049/
	 user: sparker
25/09/30 17:54:21 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1759095470586_0049 with large data and queued
=================================================================

25/09/30 17:54:21 INFO ShutdownHookManager: Deleting directory /tmp/spark-cf0bc3e3-3f87-4215-bb34-548bafa7d0ac
25/09/30 17:54:21 INFO ShutdownHookManager: Deleting directory /tmp/spark-19abe336-7e4f-4359-876c-4689af2b5ce7
/home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1759095470586_0049
Failed to download Spark logs, we'll retry in next iteration 1: 500 Server Error: Server Error for url: http://localhost:18080/api/v1/applications/application_1759095470586_0049/logs
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1759095470586_0049.zip
====================================================================================================
Benchmark Name: svm
Time to create app instrumentation: 0.06 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.18 seconds
Time to create stages instrumentation: 1.72 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 51.31 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
59.487456
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
59.893729
====================================================================================================
SQL PLANS: 0 | JOBS: 107 | JOBS WITHOUT SQL PLAN: 107 | STAGES: 210 | STAGES SKIPPED: 1 | TASK: 32849 TASK_WITH_ERRORS: 0 |
Get distributions elapsed_time: 0.171410 seconds
Starting parallel processing.
Time taken for parallel processing: 0.10646796226501465 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
59.989367
====================================================================================================
Finished application vectorization for application_1759095470586_0049_svm_large
Saving optimized workload into MongoDB: {'_id': 'application_1759095470586_0049_svm_large', 'experiment_id': 'svm_q1_evaluation', 'experiment_iteration': 5, 'target_workload': {'id': 'application_1753112283118_0437_svm_large', 'execution_time': 2020, 'name': 'svm', 'input_data_size': 'large', 'configuration': {'driver_cores': 1, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 5, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 200, 'task_cpus': 1}}, 'objective_function_real': 3420.0000000000027, 'acquisition_function_score': -330.87784383297185, 'resource_usage_value': 22.0, 'execution_time': 3420, 'configuration': {'driver_cores': 2, 'driver_memory': 3, 'executor_cores': 2, 'executor_instances': 2, 'executor_memory': 4, 'sql_shuffle_partitions': 150, 'task_cpus': 1}, 'execution_time_error': 3078, 'objective_function_predict': 341.99999999999983, 'beta': None, 'alpha': None, 'repeated_config': True, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1759095470586_0049_svm_large documents into MongoDB
[TurBO] Step 6 | -EI=-353.920 | mu_pred(T)=352.08 | cfg=[  1   2   1   1   5 300   1]
[TurBO][CAS] f_pred=542.18 vs f_th=3875.20 -> RUN
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: turbo_bo_baseline, config: driver_cores=1 driver_memory=2 executor_cores=1 executor_instances=1 executor_memory=5 sql_shuffle_partitions=300 task_cpus=1
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/svm/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
patching args=
start SVM bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.SVMWithSGDExample           --master yarn --num-executors 1 --executor-cores 1 --executor-memory 5g --driver-memory 2g --driver-cores 1 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --numIterations 100 --storageLevel MEMORY_ONLY --stepSize 1.0 --regParam 0.01 hdfs://172.30.0.20:9000/HiBench/SVM/Input/large
25/09/30 17:56:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/09/30 17:56:13 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/09/30 17:56:14 INFO Configuration: resource-types.xml not found
25/09/30 17:56:14 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/09/30 17:56:14 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/09/30 17:56:14 INFO Client: Will allocate AM container, with 2432 MB memory including 384 MB overhead
25/09/30 17:56:14 INFO Client: Setting up container launch context for our AM
25/09/30 17:56:14 INFO Client: Setting up the launch environment for our AM container
25/09/30 17:56:14 INFO Client: Preparing resources for our AM container
25/09/30 17:56:14 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/09/30 17:56:15 INFO Client: Uploading resource file:/tmp/spark-0da4ac31-3cdc-4a9f-9c04-f96809963118/__spark_libs__7649572214009672002.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0050/__spark_libs__7649572214009672002.zip
25/09/30 17:56:16 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0050/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/09/30 17:56:19 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0050/sparkbench.conf
25/09/30 17:56:20 INFO Client: Uploading resource file:/tmp/spark-0da4ac31-3cdc-4a9f-9c04-f96809963118/__spark_conf__743678784449333422.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0050/__spark_conf__.zip
25/09/30 17:56:20 INFO SecurityManager: Changing view acls to: sparker
25/09/30 17:56:20 INFO SecurityManager: Changing modify acls to: sparker
25/09/30 17:56:20 INFO SecurityManager: Changing view acls groups to:
25/09/30 17:56:20 INFO SecurityManager: Changing modify acls groups to:
25/09/30 17:56:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/09/30 17:56:20 INFO Client: Submitting application application_1759095470586_0050 to ResourceManager
25/09/30 17:56:20 INFO YarnClientImpl: Submitted application application_1759095470586_0050

=================================================================
Detected application_1759095470586_0050
=================================================================

25/09/30 17:56:21 INFO Client: Application report for application_1759095470586_0050 (state: ACCEPTED)
25/09/30 17:56:21 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1759254980526
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0050/
	 user: sparker
25/09/30 17:56:22 INFO Client: Application report for application_1759095470586_0050 (state: ACCEPTED)
25/09/30 17:56:23 INFO Client: Application report for application_1759095470586_0050 (state: ACCEPTED)
25/09/30 17:56:24 INFO Client: Application report for application_1759095470586_0050 (state: ACCEPTED)
25/09/30 17:56:25 INFO Client: Application report for application_1759095470586_0050 (state: ACCEPTED)
25/09/30 17:56:26 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-3
	 ApplicationMaster RPC port: 36545
	 queue: default
	 start time: 1759254980526
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0050/
	 user: sparker
25/09/30 20:43:50 INFO Client: Application report for application_1759095470586_0050 (state: FINISHED)
25/09/30 20:43:50 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-3
	 ApplicationMaster RPC port: 36545
	 queue: default
	 start time: 1759254980526
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0050/
	 user: sparker
25/09/30 20:43:51 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1759095470586_0050 with large data and queued
=================================================================

25/09/30 20:43:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-b7fb9514-106e-4279-997f-ac252a5e8742
25/09/30 20:43:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-0da4ac31-3cdc-4a9f-9c04-f96809963118
/home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1759095470586_0050
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1759095470586_0050.zip
====================================================================================================
Benchmark Name: svm
Time to create app instrumentation: 0.03 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.06 seconds
Time to create stages instrumentation: 0.53 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 21.20 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
24.484140
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
24.663893
====================================================================================================
SQL PLANS: 0 | JOBS: 107 | JOBS WITHOUT SQL PLAN: 107 | STAGES: 210 | STAGES SKIPPED: 1 | TASK: 32825 TASK_WITH_ERRORS: 0 |
Get distributions elapsed_time: 0.039137 seconds
Starting parallel processing.
Time taken for parallel processing: 0.04247879981994629 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
24.686023
====================================================================================================
Finished application vectorization for application_1759095470586_0050_svm_large
Saving optimized workload into MongoDB: {'_id': 'application_1759095470586_0050_svm_large', 'experiment_id': 'svm_q1_evaluation', 'experiment_iteration': 6, 'target_workload': {'id': 'application_1753112283118_0437_svm_large', 'execution_time': 2020, 'name': 'svm', 'input_data_size': 'large', 'configuration': {'driver_cores': 1, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 5, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 200, 'task_cpus': 1}}, 'objective_function_real': 10044.000000000005, 'acquisition_function_score': -353.919610191122, 'resource_usage_value': 7.0, 'execution_time': 10044, 'configuration': {'driver_cores': 1, 'driver_memory': 2, 'executor_cores': 1, 'executor_instances': 1, 'executor_memory': 5, 'sql_shuffle_partitions': 300, 'task_cpus': 1}, 'execution_time_error': 9692, 'objective_function_predict': 351.99999999999994, 'beta': None, 'alpha': None, 'repeated_config': True, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1759095470586_0050_svm_large documents into MongoDB
[TurBO] Step 7 | -EI=-587.861 | mu_pred(T)=375.43 | cfg=[  2   3   4   2   3 150   2]
[TurBO][CAS] f_pred=262.15 vs f_th=4903.33 -> RUN
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: turbo_bo_baseline, config: driver_cores=2 driver_memory=3 executor_cores=4 executor_instances=2 executor_memory=3 sql_shuffle_partitions=150 task_cpus=2
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/svm/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
patching args=
start SVM bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.SVMWithSGDExample           --master yarn --num-executors 2 --executor-cores 4 --executor-memory 3g --driver-memory 3g --driver-cores 2 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --numIterations 100 --storageLevel MEMORY_ONLY --stepSize 1.0 --regParam 0.01 hdfs://172.30.0.20:9000/HiBench/SVM/Input/large
25/09/30 20:44:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/09/30 20:44:38 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/09/30 20:44:39 INFO Configuration: resource-types.xml not found
25/09/30 20:44:39 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/09/30 20:44:39 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/09/30 20:44:39 INFO Client: Will allocate AM container, with 3456 MB memory including 384 MB overhead
25/09/30 20:44:39 INFO Client: Setting up container launch context for our AM
25/09/30 20:44:39 INFO Client: Setting up the launch environment for our AM container
25/09/30 20:44:39 INFO Client: Preparing resources for our AM container
25/09/30 20:44:39 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/09/30 20:44:40 INFO Client: Uploading resource file:/tmp/spark-10e93d08-1ed1-42c4-a3f8-ad386d11f50c/__spark_libs__2228131683467506231.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0051/__spark_libs__2228131683467506231.zip
25/09/30 20:44:42 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0051/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/09/30 20:44:44 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0051/sparkbench.conf
25/09/30 20:44:45 INFO Client: Uploading resource file:/tmp/spark-10e93d08-1ed1-42c4-a3f8-ad386d11f50c/__spark_conf__8997150322818605760.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0051/__spark_conf__.zip
25/09/30 20:44:45 INFO SecurityManager: Changing view acls to: sparker
25/09/30 20:44:45 INFO SecurityManager: Changing modify acls to: sparker
25/09/30 20:44:45 INFO SecurityManager: Changing view acls groups to:
25/09/30 20:44:45 INFO SecurityManager: Changing modify acls groups to:
25/09/30 20:44:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/09/30 20:44:45 INFO Client: Submitting application application_1759095470586_0051 to ResourceManager
25/09/30 20:44:45 INFO YarnClientImpl: Submitted application application_1759095470586_0051

=================================================================
Detected application_1759095470586_0051
=================================================================

25/09/30 20:44:46 INFO Client: Application report for application_1759095470586_0051 (state: ACCEPTED)
25/09/30 20:44:46 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1759265085426
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0051/
	 user: sparker
25/09/30 20:44:47 INFO Client: Application report for application_1759095470586_0051 (state: ACCEPTED)
25/09/30 20:44:48 INFO Client: Application report for application_1759095470586_0051 (state: ACCEPTED)
25/09/30 20:44:49 INFO Client: Application report for application_1759095470586_0051 (state: ACCEPTED)
25/09/30 20:44:50 INFO Client: Application report for application_1759095470586_0051 (state: ACCEPTED)
25/09/30 20:44:51 INFO Client: Application report for application_1759095470586_0051 (state: ACCEPTED)
25/09/30 20:44:52 INFO Client: Application report for application_1759095470586_0051 (state: ACCEPTED)
25/09/30 20:44:53 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-1
	 ApplicationMaster RPC port: 41137
	 queue: default
	 start time: 1759265085426
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0051/
	 user: sparker
25/09/30 21:42:08 INFO Client: Application report for application_1759095470586_0051 (state: FINISHED)
25/09/30 21:42:08 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-1
	 ApplicationMaster RPC port: 41137
	 queue: default
	 start time: 1759265085426
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0051/
	 user: sparker
25/09/30 21:42:09 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1759095470586_0051 with large data and queued
=================================================================

25/09/30 21:42:09 INFO ShutdownHookManager: Deleting directory /tmp/spark-10e93d08-1ed1-42c4-a3f8-ad386d11f50c
25/09/30 21:42:09 INFO ShutdownHookManager: Deleting directory /tmp/spark-e06e93fa-83e7-4771-b382-e369234d14a2
/home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1759095470586_0051
Failed to download Spark logs, we'll retry in next iteration 1: 500 Server Error: Server Error for url: http://localhost:18080/api/v1/applications/application_1759095470586_0051/logs
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1759095470586_0051.zip
====================================================================================================
Benchmark Name: svm
Time to create app instrumentation: 0.03 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.06 seconds
Time to create stages instrumentation: 0.54 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 20.56 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
24.189986
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
24.341669
====================================================================================================
SQL PLANS: 0 | JOBS: 107 | JOBS WITHOUT SQL PLAN: 107 | STAGES: 210 | STAGES SKIPPED: 1 | TASK: 32881 TASK_WITH_ERRORS: 0 |
Get distributions elapsed_time: 0.036263 seconds
Starting parallel processing.
Time taken for parallel processing: 0.03888130187988281 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
24.385977
====================================================================================================
Finished application vectorization for application_1759095470586_0051_svm_large
Saving optimized workload into MongoDB: {'_id': 'application_1759095470586_0051_svm_large', 'experiment_id': 'svm_q1_evaluation', 'experiment_iteration': 7, 'target_workload': {'id': 'application_1753112283118_0437_svm_large', 'execution_time': 2020, 'name': 'svm', 'input_data_size': 'large', 'configuration': {'driver_cores': 1, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 5, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 200, 'task_cpus': 1}}, 'objective_function_real': 3436.0000000000027, 'acquisition_function_score': -587.86138323243, 'resource_usage_value': 30.0, 'execution_time': 3436, 'configuration': {'driver_cores': 2, 'driver_memory': 3, 'executor_cores': 4, 'executor_instances': 2, 'executor_memory': 3, 'sql_shuffle_partitions': 150, 'task_cpus': 2}, 'execution_time_error': 3061, 'objective_function_predict': 375.00000000000006, 'beta': None, 'alpha': None, 'repeated_config': True, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1759095470586_0051_svm_large documents into MongoDB
[TurBO] Step 8 | -EI=-603.502 | mu_pred(T)=382.76 | cfg=[  1   3   3   1   4 100   1]
[TurBO][CAS] f_pred=55.09 vs f_th=4693.71 -> RUN
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: turbo_bo_baseline, config: driver_cores=1 driver_memory=3 executor_cores=3 executor_instances=1 executor_memory=4 sql_shuffle_partitions=100 task_cpus=1
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/svm/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
patching args=
start SVM bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.SVMWithSGDExample           --master yarn --num-executors 1 --executor-cores 3 --executor-memory 4g --driver-memory 3g --driver-cores 1 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --numIterations 100 --storageLevel MEMORY_ONLY --stepSize 1.0 --regParam 0.01 hdfs://172.30.0.20:9000/HiBench/SVM/Input/large
25/09/30 21:43:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/09/30 21:43:17 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/09/30 21:43:18 INFO Configuration: resource-types.xml not found
25/09/30 21:43:18 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/09/30 21:43:18 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/09/30 21:43:18 INFO Client: Will allocate AM container, with 3456 MB memory including 384 MB overhead
25/09/30 21:43:18 INFO Client: Setting up container launch context for our AM
25/09/30 21:43:18 INFO Client: Setting up the launch environment for our AM container
25/09/30 21:43:18 INFO Client: Preparing resources for our AM container
25/09/30 21:43:18 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/09/30 21:43:19 INFO Client: Uploading resource file:/tmp/spark-62f56832-48ba-49a3-a246-f3b42cfd4ae8/__spark_libs__3403080791907295045.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0052/__spark_libs__3403080791907295045.zip
25/09/30 21:43:20 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0052/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/09/30 21:43:24 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0052/sparkbench.conf
25/09/30 21:43:25 INFO Client: Uploading resource file:/tmp/spark-62f56832-48ba-49a3-a246-f3b42cfd4ae8/__spark_conf__8879176059358924291.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0052/__spark_conf__.zip
25/09/30 21:43:25 INFO SecurityManager: Changing view acls to: sparker
25/09/30 21:43:25 INFO SecurityManager: Changing modify acls to: sparker
25/09/30 21:43:25 INFO SecurityManager: Changing view acls groups to:
25/09/30 21:43:25 INFO SecurityManager: Changing modify acls groups to:
25/09/30 21:43:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/09/30 21:43:25 INFO Client: Submitting application application_1759095470586_0052 to ResourceManager
25/09/30 21:43:25 INFO YarnClientImpl: Submitted application application_1759095470586_0052

=================================================================
Detected application_1759095470586_0052
=================================================================

25/09/30 21:43:26 INFO Client: Application report for application_1759095470586_0052 (state: ACCEPTED)
25/09/30 21:43:26 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1759268605665
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0052/
	 user: sparker
25/09/30 21:43:27 INFO Client: Application report for application_1759095470586_0052 (state: ACCEPTED)
25/09/30 21:43:28 INFO Client: Application report for application_1759095470586_0052 (state: ACCEPTED)
25/09/30 21:43:29 INFO Client: Application report for application_1759095470586_0052 (state: ACCEPTED)
25/09/30 21:43:30 INFO Client: Application report for application_1759095470586_0052 (state: ACCEPTED)
25/09/30 21:43:31 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-1
	 ApplicationMaster RPC port: 41945
	 queue: default
	 start time: 1759268605665
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0052/
	 user: sparker
25/09/30 22:54:23 INFO Client: Application report for application_1759095470586_0052 (state: FINISHED)
25/09/30 22:54:23 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-1
	 ApplicationMaster RPC port: 41945
	 queue: default
	 start time: 1759268605665
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0052/
	 user: sparker
25/09/30 22:54:24 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1759095470586_0052 with large data and queued
=================================================================

25/09/30 22:54:24 INFO ShutdownHookManager: Deleting directory /tmp/spark-62f56832-48ba-49a3-a246-f3b42cfd4ae8
25/09/30 22:54:24 INFO ShutdownHookManager: Deleting directory /tmp/spark-a29ea1f7-0efc-4f9e-9b14-441031858dbd
/home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1759095470586_0052
Failed to download Spark logs, we'll retry in next iteration 1: 500 Server Error: Server Error for url: http://localhost:18080/api/v1/applications/application_1759095470586_0052/logs
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1759095470586_0052.zip
====================================================================================================
Benchmark Name: svm
Time to create app instrumentation: 0.03 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.06 seconds
Time to create stages instrumentation: 0.52 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 20.87 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
24.310677
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
24.458425
====================================================================================================
SQL PLANS: 0 | JOBS: 107 | JOBS WITHOUT SQL PLAN: 107 | STAGES: 210 | STAGES SKIPPED: 1 | TASK: 32841 TASK_WITH_ERRORS: 0 |
Get distributions elapsed_time: 0.041812 seconds
Starting parallel processing.
Time taken for parallel processing: 0.038665056228637695 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
24.519879
====================================================================================================
Finished application vectorization for application_1759095470586_0052_svm_large
Saving optimized workload into MongoDB: {'_id': 'application_1759095470586_0052_svm_large', 'experiment_id': 'svm_q1_evaluation', 'experiment_iteration': 8, 'target_workload': {'id': 'application_1753112283118_0437_svm_large', 'execution_time': 2020, 'name': 'svm', 'input_data_size': 'large', 'configuration': {'driver_cores': 1, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 5, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 200, 'task_cpus': 1}}, 'objective_function_real': 4253.000000000002, 'acquisition_function_score': -603.5024231383275, 'resource_usage_value': 15.0, 'execution_time': 4253, 'configuration': {'driver_cores': 1, 'driver_memory': 3, 'executor_cores': 3, 'executor_instances': 1, 'executor_memory': 4, 'sql_shuffle_partitions': 100, 'task_cpus': 1}, 'execution_time_error': 3871, 'objective_function_predict': 381.9999999999999, 'beta': None, 'alpha': None, 'repeated_config': True, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1759095470586_0052_svm_large documents into MongoDB
[TurBO] Step 9 | -EI=-621.850 | mu_pred(T)=392.07 | cfg=[  2   2   2   1   2 150   2]
[TurBO][CAS] f_pred=277.46 vs f_th=4638.62 -> RUN
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: turbo_bo_baseline, config: driver_cores=2 driver_memory=2 executor_cores=2 executor_instances=1 executor_memory=2 sql_shuffle_partitions=150 task_cpus=2
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/svm/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
patching args=
start SVM bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.SVMWithSGDExample           --master yarn --num-executors 1 --executor-cores 2 --executor-memory 2g --driver-memory 2g --driver-cores 2 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --numIterations 100 --storageLevel MEMORY_ONLY --stepSize 1.0 --regParam 0.01 hdfs://172.30.0.20:9000/HiBench/SVM/Input/large
25/09/30 22:55:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/09/30 22:55:35 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/09/30 22:55:36 INFO Configuration: resource-types.xml not found
25/09/30 22:55:36 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/09/30 22:55:36 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/09/30 22:55:36 INFO Client: Will allocate AM container, with 2432 MB memory including 384 MB overhead
25/09/30 22:55:36 INFO Client: Setting up container launch context for our AM
25/09/30 22:55:36 INFO Client: Setting up the launch environment for our AM container
25/09/30 22:55:36 INFO Client: Preparing resources for our AM container
25/09/30 22:55:36 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/09/30 22:55:37 INFO Client: Uploading resource file:/tmp/spark-1cf24982-a96d-4b6d-9069-d7a1adf3c797/__spark_libs__5745255134859685410.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0053/__spark_libs__5745255134859685410.zip
25/09/30 22:55:39 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0053/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/09/30 22:55:42 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0053/sparkbench.conf
25/09/30 22:55:42 INFO Client: Uploading resource file:/tmp/spark-1cf24982-a96d-4b6d-9069-d7a1adf3c797/__spark_conf__4072501914455243538.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0053/__spark_conf__.zip
25/09/30 22:55:42 INFO SecurityManager: Changing view acls to: sparker
25/09/30 22:55:42 INFO SecurityManager: Changing modify acls to: sparker
25/09/30 22:55:42 INFO SecurityManager: Changing view acls groups to:
25/09/30 22:55:42 INFO SecurityManager: Changing modify acls groups to:
25/09/30 22:55:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/09/30 22:55:43 INFO Client: Submitting application application_1759095470586_0053 to ResourceManager
25/09/30 22:55:43 INFO YarnClientImpl: Submitted application application_1759095470586_0053

=================================================================
Detected application_1759095470586_0053
=================================================================

25/09/30 22:55:44 INFO Client: Application report for application_1759095470586_0053 (state: ACCEPTED)
25/09/30 22:55:44 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1759272943052
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0053/
	 user: sparker
25/09/30 22:55:45 INFO Client: Application report for application_1759095470586_0053 (state: ACCEPTED)
25/09/30 22:55:46 INFO Client: Application report for application_1759095470586_0053 (state: ACCEPTED)
25/09/30 22:55:47 INFO Client: Application report for application_1759095470586_0053 (state: ACCEPTED)
25/09/30 22:55:48 INFO Client: Application report for application_1759095470586_0053 (state: ACCEPTED)
25/09/30 22:55:49 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-2
	 ApplicationMaster RPC port: 44601
	 queue: default
	 start time: 1759272943052
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0053/
	 user: sparker
25/10/01 01:45:10 INFO Client: Application report for application_1759095470586_0053 (state: FINISHED)
25/10/01 01:45:10 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-2
	 ApplicationMaster RPC port: 44601
	 queue: default
	 start time: 1759272943052
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0053/
	 user: sparker
25/10/01 01:45:11 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1759095470586_0053 with large data and queued
=================================================================

25/10/01 01:45:11 INFO ShutdownHookManager: Deleting directory /tmp/spark-1cf24982-a96d-4b6d-9069-d7a1adf3c797
25/10/01 01:45:11 INFO ShutdownHookManager: Deleting directory /tmp/spark-527920b9-1623-4235-abb9-d81bdba7901d
/home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1759095470586_0053
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1759095470586_0053.zip
====================================================================================================
Benchmark Name: svm
Time to create app instrumentation: 0.03 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.06 seconds
Time to create stages instrumentation: 0.53 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 21.07 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
24.703629
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
24.869065
====================================================================================================
SQL PLANS: 0 | JOBS: 107 | JOBS WITHOUT SQL PLAN: 107 | STAGES: 210 | STAGES SKIPPED: 1 | TASK: 32833 TASK_WITH_ERRORS: 0 |
Get distributions elapsed_time: 0.038051 seconds
Starting parallel processing.
Time taken for parallel processing: 0.03949856758117676 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
24.892473
====================================================================================================
Finished application vectorization for application_1759095470586_0053_svm_large
Saving optimized workload into MongoDB: {'_id': 'application_1759095470586_0053_svm_large', 'experiment_id': 'svm_q1_evaluation', 'experiment_iteration': 9, 'target_workload': {'id': 'application_1753112283118_0437_svm_large', 'execution_time': 2020, 'name': 'svm', 'input_data_size': 'large', 'configuration': {'driver_cores': 1, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 5, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 200, 'task_cpus': 1}}, 'objective_function_real': 10160.999999999998, 'acquisition_function_score': -621.850463737715, 'resource_usage_value': 8.0, 'execution_time': 10161, 'configuration': {'driver_cores': 2, 'driver_memory': 2, 'executor_cores': 2, 'executor_instances': 1, 'executor_memory': 2, 'sql_shuffle_partitions': 150, 'task_cpus': 2}, 'execution_time_error': 9769, 'objective_function_predict': 392.0, 'beta': None, 'alpha': None, 'repeated_config': True, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1759095470586_0053_svm_large documents into MongoDB
[TurBO] Step 10 | -EI=-776.128 | mu_pred(T)=415.44 | cfg=[  2   2   2   4   5 200   1]
[TurBO][CAS] f_pred=159.60 vs f_th=5252.22 -> RUN
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: turbo_bo_baseline, config: driver_cores=2 driver_memory=2 executor_cores=2 executor_instances=4 executor_memory=5 sql_shuffle_partitions=200 task_cpus=1
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/svm/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
patching args=
start SVM bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.SVMWithSGDExample           --master yarn --num-executors 4 --executor-cores 2 --executor-memory 5g --driver-memory 2g --driver-cores 2 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --numIterations 100 --storageLevel MEMORY_ONLY --stepSize 1.0 --regParam 0.01 hdfs://172.30.0.20:9000/HiBench/SVM/Input/large
25/10/01 01:46:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/10/01 01:46:04 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/10/01 01:46:05 INFO Configuration: resource-types.xml not found
25/10/01 01:46:05 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/10/01 01:46:05 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/10/01 01:46:05 INFO Client: Will allocate AM container, with 2432 MB memory including 384 MB overhead
25/10/01 01:46:05 INFO Client: Setting up container launch context for our AM
25/10/01 01:46:05 INFO Client: Setting up the launch environment for our AM container
25/10/01 01:46:05 INFO Client: Preparing resources for our AM container
25/10/01 01:46:05 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/10/01 01:46:07 INFO Client: Uploading resource file:/tmp/spark-7246f08e-4974-45f8-96a4-35fb23b44592/__spark_libs__7685727195435860952.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0054/__spark_libs__7685727195435860952.zip
25/10/01 01:46:08 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0054/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/10/01 01:46:11 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0054/sparkbench.conf
25/10/01 01:46:12 INFO Client: Uploading resource file:/tmp/spark-7246f08e-4974-45f8-96a4-35fb23b44592/__spark_conf__5761390706213631666.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0054/__spark_conf__.zip
25/10/01 01:46:12 INFO SecurityManager: Changing view acls to: sparker
25/10/01 01:46:12 INFO SecurityManager: Changing modify acls to: sparker
25/10/01 01:46:12 INFO SecurityManager: Changing view acls groups to:
25/10/01 01:46:12 INFO SecurityManager: Changing modify acls groups to:
25/10/01 01:46:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/10/01 01:46:12 INFO Client: Submitting application application_1759095470586_0054 to ResourceManager
25/10/01 01:46:12 INFO YarnClientImpl: Submitted application application_1759095470586_0054

=================================================================
Detected application_1759095470586_0054
=================================================================

25/10/01 01:46:13 INFO Client: Application report for application_1759095470586_0054 (state: ACCEPTED)
25/10/01 01:46:13 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1759283172741
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0054/
	 user: sparker
25/10/01 01:46:14 INFO Client: Application report for application_1759095470586_0054 (state: ACCEPTED)
25/10/01 01:46:15 INFO Client: Application report for application_1759095470586_0054 (state: ACCEPTED)
25/10/01 01:46:16 INFO Client: Application report for application_1759095470586_0054 (state: ACCEPTED)
25/10/01 01:46:17 INFO Client: Application report for application_1759095470586_0054 (state: ACCEPTED)
25/10/01 01:46:18 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-2
	 ApplicationMaster RPC port: 40089
	 queue: default
	 start time: 1759283172741
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0054/
	 user: sparker
25/10/01 02:16:51 INFO Client: Application report for application_1759095470586_0054 (state: FINISHED)
25/10/01 02:16:51 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-2
	 ApplicationMaster RPC port: 40089
	 queue: default
	 start time: 1759283172741
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0054/
	 user: sparker
25/10/01 02:16:52 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1759095470586_0054 with large data and queued
=================================================================

25/10/01 02:16:52 INFO ShutdownHookManager: Deleting directory /tmp/spark-c1acf59e-94e4-4928-a896-ac7279bae0cc
25/10/01 02:16:52 INFO ShutdownHookManager: Deleting directory /tmp/spark-7246f08e-4974-45f8-96a4-35fb23b44592
/home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1759095470586_0054
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1759095470586_0054.zip
====================================================================================================
Benchmark Name: svm
Time to create app instrumentation: 0.03 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.08 seconds
Time to create stages instrumentation: 0.54 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 22.16 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
25.607307
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
25.754535
====================================================================================================
SQL PLANS: 0 | JOBS: 107 | JOBS WITHOUT SQL PLAN: 107 | STAGES: 210 | STAGES SKIPPED: 1 | TASK: 32881 TASK_WITH_ERRORS: 0 |
Get distributions elapsed_time: 0.037292 seconds
Starting parallel processing.
Time taken for parallel processing: 0.03955817222595215 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
25.786509
====================================================================================================
Finished application vectorization for application_1759095470586_0054_svm_large
Saving optimized workload into MongoDB: {'_id': 'application_1759095470586_0054_svm_large', 'experiment_id': 'svm_q1_evaluation', 'experiment_iteration': 10, 'target_workload': {'id': 'application_1753112283118_0437_svm_large', 'execution_time': 2020, 'name': 'svm', 'input_data_size': 'large', 'configuration': {'driver_cores': 1, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 5, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 200, 'task_cpus': 1}}, 'objective_function_real': 1833.9999999999993, 'acquisition_function_score': -776.128079305726, 'resource_usage_value': 44.0, 'execution_time': 1834, 'configuration': {'driver_cores': 2, 'driver_memory': 2, 'executor_cores': 2, 'executor_instances': 4, 'executor_memory': 5, 'sql_shuffle_partitions': 200, 'task_cpus': 1}, 'execution_time_error': 1419, 'objective_function_predict': 415.0, 'beta': None, 'alpha': None, 'repeated_config': True, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1759095470586_0054_svm_large documents into MongoDB

=== Metrics (10 iterations / real evals) — TurBO baseline ===
T best ↓ : 1834.00  (found at i=10)
T first ↓: 2722.00
SU (%) ↑ : 9.21
TC ↓     : 49104.00
Hit@0.10 ↑ : 10.00
nAOCC ↓  : 1.6774
