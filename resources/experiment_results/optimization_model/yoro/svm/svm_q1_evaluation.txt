Target workload: id='application_1753112283118_0437_svm_large' time_stamp=datetime.datetime(2025, 10, 1, 5, 41, 58, 804606) app_name='SVM with Params(100,1.0,0.01,hdfs://172.18.0.20:9000/HiBench/SVM/Input/large,MEMORY_ONLY)' app_benchmark_workload='svm' time_execution=2020 dataset_size=4013178096260.0 app_benchmark_data_size=<InputDataSizeType.LARGE: 'large'> environment=Environment(driver_cores=1, driver_memory_gb=2, dynamic_allocation=False, executor_cores=5, executor_instances=3, executor_memory_gb=3, sql_adaptive=False, sql_shuffle_partitions=200, task_cpus=1) time_resources=None vector_metrics_yoro=[38444.362085914814, 883.0, 805566.0, 168783.89980209994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8869253103495576, 0.0, 255.0, 8.052608702638851, 0.5053611028554446, 0.0, 136.0, 4.382938594996994, 65603.86817859673, 0.0, 12814992.0, 595947.3616389172, 0.0, 0.0, 0.0, 0.0, 65324.47486340047, 0.0, 9611244.0, 422305.88583454565, 2.7460734779726117, 0.0, 801.0, 35.03602582458729, 91748659.06723669, 0.0, 144010911.0, 44654531.36373677, 2.367435586749274, 0.0, 1830.0, 20.5983197556201, 1906324.263277017, 424800.0, 653892600.0, 7359114.335876835, 610.0187924373014, 0.0, 11954.0, 631.8629129796302, 336807781.0955396, 347600.0, 1627650400.0, 176892480.33583447, 73.81212135067786, 0.0, 11067.0, 483.3809034349173, 0.0326924395875723, 0.0, 139.0, 0.877072303514219, 0.43741569694337123, 0.0, 142.0, 4.075381174915614] vector_metrics_garralda=[0.17522917066310897, 0.5732991452395171, 0.155092070055617, 0.06574958268938834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07228129085249697, -1.0098204941898117, 0.9648391838471837, 0.008611316243076069, 0.07249557451207199, -1.0112069877735153, 0.9607941546092333, 0.008922378531755008, -1.7484983525419702, 1.0543815090347284, 0.6175206104825947, 0.10501171540424734, 0.0, 0.0, 0.0, 0.0, -1.5887185621355964, 0.9898190174925301, 0.6095149097811504, 0.10741197633623462, 0.044961139345578785, -1.025794678716364, 0.9932506939081438, 0.004584435453380944, -1.6388163621888607, 0.9321512504678565, 0.6494756696925067, 0.10268232540143188, 0.1389628782662683, -1.10219037019325, 0.9926720373381562, 0.013408121651896006, -0.08178628164807882, 0.001413005621976629, 0.5753464086207696, 0.09965546614276898, -0.1441871037889432, 0.8440422183284433, 0.1515708692098414, 0.06632651169097631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.8120284947429111, -0.22375025282055014, 0.9889446451995539, 0.029801830112556965, -1.5559476147202935, 1.0030328700007232, 0.5462682273523731, 0.11065977602800123, -1.3477594250101885, 1.3513434269981455, 0.26063086102813926, 0.13045960072320878, -1.5559476147202935, 1.0030328700007232, 0.5462682273523731, 0.11065977602800123, -1.932043105435729, 1.9808394457430265, 0.2470533008372015, 0.10264561717823051, 0.08473460485452482, -0.06437681770278098, 0.46682543014995187, 0.18049841578666342, -1.5773822082040954, 0.7389704030695131, 0.7203509666095957, 0.08235457596486802, -2.041194832484438, 1.214693816922734, 0.6245878441001256, 0.10407577122850739, 0.12301576379370215, 0.7819332851544685, 0.054093703373807756, 0.03035497812611543, -0.32707235383753464, 0.7154180463094952, 0.4441503119829657, 0.10667553128303871] resource_usage=None resource_shape=None
Workload reference type(workload_ref)=<class 'list'> | len(workload_ref[0])=76
[[38444.362085914814, 883.0, 805566.0, 168783.89980209994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8869253103495576, 0.0, 255.0, 8.052608702638851, 0.5053611028554446, 0.0, 136.0, 4.382938594996994, 65603.86817859673, 0.0, 12814992.0, 595947.3616389172, 0.0, 0.0, 0.0, 0.0, 65324.47486340047, 0.0, 9611244.0, 422305.88583454565, 2.7460734779726117, 0.0, 801.0, 35.03602582458729, 91748659.06723669, 0.0, 144010911.0, 44654531.36373677, 2.367435586749274, 0.0, 1830.0, 20.5983197556201, 1906324.263277017, 424800.0, 653892600.0, 7359114.335876835, 610.0187924373014, 0.0, 11954.0, 631.8629129796302, 336807781.0955396, 347600.0, 1627650400.0, 176892480.33583447, 73.81212135067786, 0.0, 11067.0, 483.3809034349173, 0.0326924395875723, 0.0, 139.0, 0.877072303514219, 0.43741569694337123, 0.0, 142.0, 4.075381174915614, 3737.563356999308, 1, 2, 5, 3, 3, 200, 1]]
Workload sd setting reference: [[1, 2, 5, 3, 3, 200, 1]]
Workload execution time reference: [2020]
[Candidate Space] grid_size=10080, n_candidates=256 (n=2)
[Candidate Space]  Generated 256 candidates via Sobol.
Total characterized workloads: 760 *******
Workload reference type(workload_characterization_extended_features_v2)=<class 'list'> | len(workload_characterization_extended_features_v2[0])=76
[YORO/SBO] Selected 10 candidates via GP+EI over oracle.
cfg=[  1   2   3   4   3 150   2]
cfg=[  1   2   4   3   3 200   1]
cfg=[  1   3   4   3   3 200   1]
cfg=[  1   2   2   2   3 200   1]
cfg=[  1   2   2   3   3 250   1]
cfg=[  1   2   4   2   2 150   1]
cfg=[  1   2   1   4   4 200   1]
cfg=[  1   2   1   1   5 300   1]
cfg=[  2   3   3   3   3 200   1]
cfg=[  2   2   2   1   2 200   2]
[YORO/SBO] Iter 1: T_pred=3332.63 | cfg=[  1   2   3   4   3 150   2]
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: yoro_bo_baseline, config: driver_cores=1 driver_memory=2 executor_cores=3 executor_instances=4 executor_memory=3 sql_shuffle_partitions=150 task_cpus=2
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/svm/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
patching args=
start SVM bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.SVMWithSGDExample           --master yarn --num-executors 4 --executor-cores 3 --executor-memory 3g --driver-memory 2g --driver-cores 1 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --numIterations 100 --storageLevel MEMORY_ONLY --stepSize 1.0 --regParam 0.01 hdfs://172.30.0.20:9000/HiBench/SVM/Input/large
25/10/01 05:42:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/10/01 05:42:58 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/10/01 05:43:00 INFO Configuration: resource-types.xml not found
25/10/01 05:43:00 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/10/01 05:43:00 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/10/01 05:43:00 INFO Client: Will allocate AM container, with 2432 MB memory including 384 MB overhead
25/10/01 05:43:00 INFO Client: Setting up container launch context for our AM
25/10/01 05:43:00 INFO Client: Setting up the launch environment for our AM container
25/10/01 05:43:00 INFO Client: Preparing resources for our AM container
25/10/01 05:43:00 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/10/01 05:43:01 INFO Client: Uploading resource file:/tmp/spark-b1c5af72-32cf-49fb-bd90-d9e8af8ed6f9/__spark_libs__683827846101593462.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0055/__spark_libs__683827846101593462.zip
25/10/01 05:43:02 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0055/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/10/01 05:43:05 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0055/sparkbench.conf
25/10/01 05:43:05 INFO Client: Uploading resource file:/tmp/spark-b1c5af72-32cf-49fb-bd90-d9e8af8ed6f9/__spark_conf__4659629852257500948.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0055/__spark_conf__.zip
25/10/01 05:43:05 INFO SecurityManager: Changing view acls to: sparker
25/10/01 05:43:05 INFO SecurityManager: Changing modify acls to: sparker
25/10/01 05:43:05 INFO SecurityManager: Changing view acls groups to:
25/10/01 05:43:05 INFO SecurityManager: Changing modify acls groups to:
25/10/01 05:43:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/10/01 05:43:05 INFO Client: Submitting application application_1759095470586_0055 to ResourceManager
25/10/01 05:43:06 INFO YarnClientImpl: Submitted application application_1759095470586_0055

=================================================================
Detected application_1759095470586_0055
=================================================================

25/10/01 05:43:07 INFO Client: Application report for application_1759095470586_0055 (state: ACCEPTED)
25/10/01 05:43:07 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1759297385996
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0055/
	 user: sparker
25/10/01 05:43:08 INFO Client: Application report for application_1759095470586_0055 (state: ACCEPTED)
25/10/01 05:43:09 INFO Client: Application report for application_1759095470586_0055 (state: ACCEPTED)
25/10/01 05:43:10 INFO Client: Application report for application_1759095470586_0055 (state: ACCEPTED)
25/10/01 05:43:11 INFO Client: Application report for application_1759095470586_0055 (state: ACCEPTED)
25/10/01 05:43:12 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-2
	 ApplicationMaster RPC port: 44223
	 queue: default
	 start time: 1759297385996
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0055/
	 user: sparker
25/10/01 06:55:49 INFO Client: Application report for application_1759095470586_0055 (state: FINISHED)
25/10/01 06:55:49 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-2
	 ApplicationMaster RPC port: 44223
	 queue: default
	 start time: 1759297385996
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0055/
	 user: sparker
25/10/01 06:55:50 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1759095470586_0055 with large data and queued
=================================================================

25/10/01 06:55:50 INFO ShutdownHookManager: Deleting directory /tmp/spark-b1c5af72-32cf-49fb-bd90-d9e8af8ed6f9
25/10/01 06:55:50 INFO ShutdownHookManager: Deleting directory /tmp/spark-3deb2e08-db0a-41fa-b1dc-69a82c06431a
/home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1759095470586_0055
Failed to download Spark logs, we'll retry in next iteration 1: 500 Server Error: Server Error for url: http://localhost:18080/api/v1/applications/application_1759095470586_0055/logs
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1759095470586_0055.zip
====================================================================================================
Benchmark Name: svm
Time to create app instrumentation: 0.05 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.16 seconds
Time to create stages instrumentation: 1.31 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 48.89 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
56.361058
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
56.694641
====================================================================================================
SQL PLANS: 0 | JOBS: 107 | JOBS WITHOUT SQL PLAN: 107 | STAGES: 210 | STAGES SKIPPED: 1 | TASK: 32913 TASK_WITH_ERRORS: 0 |
Get distributions elapsed_time: 0.141108 seconds
Starting parallel processing.
Time taken for parallel processing: 0.12549805641174316 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
56.844111
====================================================================================================
Finished application vectorization for application_1759095470586_0055_svm_large
Saving optimized workload into MongoDB: {'_id': 'application_1759095470586_0055_svm_large', 'experiment_id': 'svm_q1_evaluation', 'experiment_iteration': 1, 'target_workload': {'id': 'application_1753112283118_0437_svm_large', 'execution_time': 2020, 'name': 'svm', 'input_data_size': 'large', 'configuration': {'driver_cores': 1, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 5, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 200, 'task_cpus': 1}}, 'objective_function_real': 4358.0, 'acquisition_function_score': 3332.63, 'resource_usage_value': 38.0, 'execution_time': 4358, 'configuration': {'driver_cores': 1, 'driver_memory': 2, 'executor_cores': 3, 'executor_instances': 4, 'executor_memory': 3, 'sql_shuffle_partitions': 150, 'task_cpus': 2}, 'execution_time_error': 1026, 'objective_function_predict': 3332.630000000002, 'beta': None, 'alpha': None, 'repeated_config': None, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1759095470586_0055_svm_large documents into MongoDB

======================================================================================================================================================
[YORO/SBO] Evaluated (success #1):
    T_real=4358.00 | T_pred=3332.63 | OF_real=4358.00
    cfg=[  1   2   3   4   3 150   2]
======================================================================================================================================================

[YORO/SBO] Iter 2: T_pred=3340.09 | cfg=[  1   2   4   3   3 200   1]
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: yoro_bo_baseline, config: driver_cores=1 driver_memory=2 executor_cores=4 executor_instances=3 executor_memory=3 sql_shuffle_partitions=200 task_cpus=1
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/svm/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
patching args=
start SVM bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.SVMWithSGDExample           --master yarn --num-executors 3 --executor-cores 4 --executor-memory 3g --driver-memory 2g --driver-cores 1 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --numIterations 100 --storageLevel MEMORY_ONLY --stepSize 1.0 --regParam 0.01 hdfs://172.30.0.20:9000/HiBench/SVM/Input/large
25/10/01 06:57:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/10/01 06:57:25 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/10/01 06:57:26 INFO Configuration: resource-types.xml not found
25/10/01 06:57:26 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/10/01 06:57:26 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/10/01 06:57:26 INFO Client: Will allocate AM container, with 2432 MB memory including 384 MB overhead
25/10/01 06:57:26 INFO Client: Setting up container launch context for our AM
25/10/01 06:57:26 INFO Client: Setting up the launch environment for our AM container
25/10/01 06:57:26 INFO Client: Preparing resources for our AM container
25/10/01 06:57:26 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/10/01 06:57:27 INFO Client: Uploading resource file:/tmp/spark-355cef35-b263-4ac3-8131-a2156f727912/__spark_libs__8291506780196475357.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0056/__spark_libs__8291506780196475357.zip
25/10/01 06:57:28 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0056/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/10/01 06:57:31 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0056/sparkbench.conf
25/10/01 06:57:32 INFO Client: Uploading resource file:/tmp/spark-355cef35-b263-4ac3-8131-a2156f727912/__spark_conf__472092398289607516.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0056/__spark_conf__.zip
25/10/01 06:57:32 INFO SecurityManager: Changing view acls to: sparker
25/10/01 06:57:32 INFO SecurityManager: Changing modify acls to: sparker
25/10/01 06:57:32 INFO SecurityManager: Changing view acls groups to:
25/10/01 06:57:32 INFO SecurityManager: Changing modify acls groups to:
25/10/01 06:57:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/10/01 06:57:32 INFO Client: Submitting application application_1759095470586_0056 to ResourceManager
25/10/01 06:57:32 INFO YarnClientImpl: Submitted application application_1759095470586_0056

=================================================================
Detected application_1759095470586_0056
=================================================================

25/10/01 06:57:33 INFO Client: Application report for application_1759095470586_0056 (state: ACCEPTED)
25/10/01 06:57:33 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1759301852301
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0056/
	 user: sparker
25/10/01 06:57:34 INFO Client: Application report for application_1759095470586_0056 (state: ACCEPTED)
25/10/01 06:57:35 INFO Client: Application report for application_1759095470586_0056 (state: ACCEPTED)
25/10/01 06:57:36 INFO Client: Application report for application_1759095470586_0056 (state: ACCEPTED)
25/10/01 06:57:37 INFO Client: Application report for application_1759095470586_0056 (state: ACCEPTED)
25/10/01 06:57:38 INFO Client: Application report for application_1759095470586_0056 (state: ACCEPTED)
25/10/01 06:57:39 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-1
	 ApplicationMaster RPC port: 37505
	 queue: default
	 start time: 1759301852301
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0056/
	 user: sparker
25/10/01 07:43:24 INFO Client: Application report for application_1759095470586_0056 (state: FINISHED)
25/10/01 07:43:24 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-1
	 ApplicationMaster RPC port: 37505
	 queue: default
	 start time: 1759301852301
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0056/
	 user: sparker
25/10/01 07:43:24 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1759095470586_0056 with large data and queued
=================================================================

25/10/01 07:43:24 INFO ShutdownHookManager: Deleting directory /tmp/spark-355cef35-b263-4ac3-8131-a2156f727912
25/10/01 07:43:24 INFO ShutdownHookManager: Deleting directory /tmp/spark-0c58b429-8a69-41bf-b82a-0363a04e5f00
/home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1759095470586_0056
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1759095470586_0056.zip
====================================================================================================
Benchmark Name: svm
Time to create app instrumentation: 0.06 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.13 seconds
Time to create stages instrumentation: 1.19 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 46.52 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
55.889740
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
56.223168
====================================================================================================
SQL PLANS: 0 | JOBS: 107 | JOBS WITHOUT SQL PLAN: 107 | STAGES: 210 | STAGES SKIPPED: 1 | TASK: 32913 TASK_WITH_ERRORS: 0 |
Get distributions elapsed_time: 0.141714 seconds
Starting parallel processing.
Time taken for parallel processing: 0.0882101058959961 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
56.372459
====================================================================================================
Finished application vectorization for application_1759095470586_0056_svm_large
Saving optimized workload into MongoDB: {'_id': 'application_1759095470586_0056_svm_large', 'experiment_id': 'svm_q1_evaluation', 'experiment_iteration': 2, 'target_workload': {'id': 'application_1753112283118_0437_svm_large', 'execution_time': 2020, 'name': 'svm', 'input_data_size': 'large', 'configuration': {'driver_cores': 1, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 5, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 200, 'task_cpus': 1}}, 'objective_function_real': 2745.0, 'acquisition_function_score': 3340.09, 'resource_usage_value': 38.0, 'execution_time': 2745, 'configuration': {'driver_cores': 1, 'driver_memory': 2, 'executor_cores': 4, 'executor_instances': 3, 'executor_memory': 3, 'sql_shuffle_partitions': 200, 'task_cpus': 1}, 'execution_time_error': 595, 'objective_function_predict': 3340.090000000003, 'beta': None, 'alpha': None, 'repeated_config': None, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1759095470586_0056_svm_large documents into MongoDB

======================================================================================================================================================
[YORO/SBO] Evaluated (success #2):
    T_real=2745.00 | T_pred=3340.09 | OF_real=2745.00
    cfg=[  1   2   4   3   3 200   1]
======================================================================================================================================================

[YORO/SBO] Iter 3: T_pred=3352.01 | cfg=[  1   3   4   3   3 200   1]
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: yoro_bo_baseline, config: driver_cores=1 driver_memory=3 executor_cores=4 executor_instances=3 executor_memory=3 sql_shuffle_partitions=200 task_cpus=1
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/svm/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
patching args=
start SVM bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.SVMWithSGDExample           --master yarn --num-executors 3 --executor-cores 4 --executor-memory 3g --driver-memory 3g --driver-cores 1 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --numIterations 100 --storageLevel MEMORY_ONLY --stepSize 1.0 --regParam 0.01 hdfs://172.30.0.20:9000/HiBench/SVM/Input/large
25/10/01 07:44:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/10/01 07:44:37 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/10/01 07:44:38 INFO Configuration: resource-types.xml not found
25/10/01 07:44:38 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/10/01 07:44:38 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/10/01 07:44:38 INFO Client: Will allocate AM container, with 3456 MB memory including 384 MB overhead
25/10/01 07:44:38 INFO Client: Setting up container launch context for our AM
25/10/01 07:44:38 INFO Client: Setting up the launch environment for our AM container
25/10/01 07:44:38 INFO Client: Preparing resources for our AM container
25/10/01 07:44:38 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/10/01 07:44:39 INFO Client: Uploading resource file:/tmp/spark-c90fc11c-defc-40b5-a81f-653133a8f4d9/__spark_libs__5502065463205256308.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0057/__spark_libs__5502065463205256308.zip
25/10/01 07:44:40 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0057/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/10/01 07:44:43 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0057/sparkbench.conf
25/10/01 07:44:43 INFO Client: Uploading resource file:/tmp/spark-c90fc11c-defc-40b5-a81f-653133a8f4d9/__spark_conf__4392210344859682670.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0057/__spark_conf__.zip
25/10/01 07:44:43 INFO SecurityManager: Changing view acls to: sparker
25/10/01 07:44:43 INFO SecurityManager: Changing modify acls to: sparker
25/10/01 07:44:43 INFO SecurityManager: Changing view acls groups to:
25/10/01 07:44:43 INFO SecurityManager: Changing modify acls groups to:
25/10/01 07:44:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/10/01 07:44:44 INFO Client: Submitting application application_1759095470586_0057 to ResourceManager
25/10/01 07:44:44 INFO YarnClientImpl: Submitted application application_1759095470586_0057

=================================================================
Detected application_1759095470586_0057
=================================================================

25/10/01 07:44:45 INFO Client: Application report for application_1759095470586_0057 (state: ACCEPTED)
25/10/01 07:44:45 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1759304684109
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0057/
	 user: sparker
25/10/01 07:44:46 INFO Client: Application report for application_1759095470586_0057 (state: ACCEPTED)
25/10/01 07:44:47 INFO Client: Application report for application_1759095470586_0057 (state: ACCEPTED)
25/10/01 07:44:48 INFO Client: Application report for application_1759095470586_0057 (state: ACCEPTED)
25/10/01 07:44:49 INFO Client: Application report for application_1759095470586_0057 (state: ACCEPTED)
25/10/01 07:44:50 INFO Client: Application report for application_1759095470586_0057 (state: ACCEPTED)
25/10/01 07:44:51 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-2
	 ApplicationMaster RPC port: 36361
	 queue: default
	 start time: 1759304684109
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0057/
	 user: sparker
25/10/01 08:25:24 INFO Client: Application report for application_1759095470586_0057 (state: FINISHED)
25/10/01 08:25:24 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-2
	 ApplicationMaster RPC port: 36361
	 queue: default
	 start time: 1759304684109
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0057/
	 user: sparker
25/10/01 08:25:25 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1759095470586_0057 with large data and queued
=================================================================

25/10/01 08:25:25 INFO ShutdownHookManager: Deleting directory /tmp/spark-c90fc11c-defc-40b5-a81f-653133a8f4d9
25/10/01 08:25:25 INFO ShutdownHookManager: Deleting directory /tmp/spark-affcc3b8-631d-445d-b20f-5e5b7f03ae06
/home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1759095470586_0057
Failed to download Spark logs, we'll retry in next iteration 1: 500 Server Error: Server Error for url: http://localhost:18080/api/v1/applications/application_1759095470586_0057/logs
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1759095470586_0057.zip
====================================================================================================
Benchmark Name: svm
Time to create app instrumentation: 0.14 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.22 seconds
Time to create stages instrumentation: 1.81 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 62.36 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
78.876073
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
79.456386
====================================================================================================
SQL PLANS: 0 | JOBS: 107 | JOBS WITHOUT SQL PLAN: 107 | STAGES: 210 | STAGES SKIPPED: 1 | TASK: 32913 TASK_WITH_ERRORS: 0 |
Get distributions elapsed_time: 0.316492 seconds
Starting parallel processing.
Time taken for parallel processing: 0.14885902404785156 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
79.699207
====================================================================================================
Finished application vectorization for application_1759095470586_0057_svm_large
Saving optimized workload into MongoDB: {'_id': 'application_1759095470586_0057_svm_large', 'experiment_id': 'svm_q1_evaluation', 'experiment_iteration': 3, 'target_workload': {'id': 'application_1753112283118_0437_svm_large', 'execution_time': 2020, 'name': 'svm', 'input_data_size': 'large', 'configuration': {'driver_cores': 1, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 5, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 200, 'task_cpus': 1}}, 'objective_function_real': 2432.999999999999, 'acquisition_function_score': 3352.01, 'resource_usage_value': 39.0, 'execution_time': 2433, 'configuration': {'driver_cores': 1, 'driver_memory': 3, 'executor_cores': 4, 'executor_instances': 3, 'executor_memory': 3, 'sql_shuffle_partitions': 200, 'task_cpus': 1}, 'execution_time_error': 919, 'objective_function_predict': 3352.0100000000025, 'beta': None, 'alpha': None, 'repeated_config': None, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1759095470586_0057_svm_large documents into MongoDB

======================================================================================================================================================
[YORO/SBO] Evaluated (success #3):
    T_real=2433.00 | T_pred=3352.01 | OF_real=2433.00
    cfg=[  1   3   4   3   3 200   1]
======================================================================================================================================================

[YORO/SBO] Iter 4: T_pred=3361.45 | cfg=[  1   2   2   2   3 200   1]
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: yoro_bo_baseline, config: driver_cores=1 driver_memory=2 executor_cores=2 executor_instances=2 executor_memory=3 sql_shuffle_partitions=200 task_cpus=1
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/svm/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
patching args=
start SVM bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.SVMWithSGDExample           --master yarn --num-executors 2 --executor-cores 2 --executor-memory 3g --driver-memory 2g --driver-cores 1 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --numIterations 100 --storageLevel MEMORY_ONLY --stepSize 1.0 --regParam 0.01 hdfs://172.30.0.20:9000/HiBench/SVM/Input/large
25/10/01 08:27:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/10/01 08:27:32 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/10/01 08:27:34 INFO Configuration: resource-types.xml not found
25/10/01 08:27:34 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/10/01 08:27:34 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/10/01 08:27:34 INFO Client: Will allocate AM container, with 2432 MB memory including 384 MB overhead
25/10/01 08:27:34 INFO Client: Setting up container launch context for our AM
25/10/01 08:27:34 INFO Client: Setting up the launch environment for our AM container
25/10/01 08:27:34 INFO Client: Preparing resources for our AM container
25/10/01 08:27:34 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/10/01 08:27:35 INFO Client: Uploading resource file:/tmp/spark-e95e1178-a218-4b1f-8471-1cc5f35fba05/__spark_libs__3762363970409421061.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0058/__spark_libs__3762363970409421061.zip
25/10/01 08:27:38 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0058/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/10/01 08:27:41 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0058/sparkbench.conf
25/10/01 08:27:41 INFO Client: Uploading resource file:/tmp/spark-e95e1178-a218-4b1f-8471-1cc5f35fba05/__spark_conf__7119604896008718861.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0058/__spark_conf__.zip
25/10/01 08:27:41 INFO SecurityManager: Changing view acls to: sparker
25/10/01 08:27:41 INFO SecurityManager: Changing modify acls to: sparker
25/10/01 08:27:41 INFO SecurityManager: Changing view acls groups to:
25/10/01 08:27:41 INFO SecurityManager: Changing modify acls groups to:
25/10/01 08:27:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/10/01 08:27:42 INFO Client: Submitting application application_1759095470586_0058 to ResourceManager
25/10/01 08:27:42 INFO YarnClientImpl: Submitted application application_1759095470586_0058

=================================================================
Detected application_1759095470586_0058
=================================================================

25/10/01 08:27:43 INFO Client: Application report for application_1759095470586_0058 (state: ACCEPTED)
25/10/01 08:27:43 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1759307262174
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0058/
	 user: sparker
25/10/01 08:27:44 INFO Client: Application report for application_1759095470586_0058 (state: ACCEPTED)
25/10/01 08:27:45 INFO Client: Application report for application_1759095470586_0058 (state: ACCEPTED)
25/10/01 08:27:46 INFO Client: Application report for application_1759095470586_0058 (state: ACCEPTED)
25/10/01 08:27:47 INFO Client: Application report for application_1759095470586_0058 (state: ACCEPTED)
25/10/01 08:27:48 INFO Client: Application report for application_1759095470586_0058 (state: ACCEPTED)
25/10/01 08:27:49 INFO Client: Application report for application_1759095470586_0058 (state: ACCEPTED)
25/10/01 08:27:50 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-3
	 ApplicationMaster RPC port: 45181
	 queue: default
	 start time: 1759307262174
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0058/
	 user: sparker
25/10/01 09:46:33 INFO Client: Application report for application_1759095470586_0058 (state: FINISHED)
25/10/01 09:46:33 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-3
	 ApplicationMaster RPC port: 45181
	 queue: default
	 start time: 1759307262174
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0058/
	 user: sparker
25/10/01 09:46:33 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1759095470586_0058 with large data and queued
=================================================================

25/10/01 09:46:33 INFO ShutdownHookManager: Deleting directory /tmp/spark-9446620f-b26e-498c-ac85-a84fbd46d6fd
25/10/01 09:46:33 INFO ShutdownHookManager: Deleting directory /tmp/spark-e95e1178-a218-4b1f-8471-1cc5f35fba05
/home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1759095470586_0058
Failed to download Spark logs, we'll retry in next iteration 1: 500 Server Error: Server Error for url: http://localhost:18080/api/v1/applications/application_1759095470586_0058/logs
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1759095470586_0058.zip
====================================================================================================
Benchmark Name: svm
Time to create app instrumentation: 0.11 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.18 seconds
Time to create stages instrumentation: 1.75 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 65.44 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
80.667093
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
81.193558
====================================================================================================
SQL PLANS: 0 | JOBS: 107 | JOBS WITHOUT SQL PLAN: 107 | STAGES: 210 | STAGES SKIPPED: 1 | TASK: 32849 TASK_WITH_ERRORS: 0 |
Get distributions elapsed_time: 0.309859 seconds
Starting parallel processing.
Time taken for parallel processing: 0.1544177532196045 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
81.534339
====================================================================================================
Finished application vectorization for application_1759095470586_0058_svm_large
Saving optimized workload into MongoDB: {'_id': 'application_1759095470586_0058_svm_large', 'experiment_id': 'svm_q1_evaluation', 'experiment_iteration': 4, 'target_workload': {'id': 'application_1753112283118_0437_svm_large', 'execution_time': 2020, 'name': 'svm', 'input_data_size': 'large', 'configuration': {'driver_cores': 1, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 5, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 200, 'task_cpus': 1}}, 'objective_function_real': 4724.000000000002, 'acquisition_function_score': 3361.45, 'resource_usage_value': 14.0, 'execution_time': 4724, 'configuration': {'driver_cores': 1, 'driver_memory': 2, 'executor_cores': 2, 'executor_instances': 2, 'executor_memory': 3, 'sql_shuffle_partitions': 200, 'task_cpus': 1}, 'execution_time_error': 1363, 'objective_function_predict': 3361.45, 'beta': None, 'alpha': None, 'repeated_config': None, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1759095470586_0058_svm_large documents into MongoDB

======================================================================================================================================================
[YORO/SBO] Evaluated (success #4):
    T_real=4724.00 | T_pred=3361.45 | OF_real=4724.00
    cfg=[  1   2   2   2   3 200   1]
======================================================================================================================================================

[YORO/SBO] Iter 5: T_pred=3370.40 | cfg=[  1   2   2   3   3 250   1]
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: yoro_bo_baseline, config: driver_cores=1 driver_memory=2 executor_cores=2 executor_instances=3 executor_memory=3 sql_shuffle_partitions=250 task_cpus=1
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/svm/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
patching args=
start SVM bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.SVMWithSGDExample           --master yarn --num-executors 3 --executor-cores 2 --executor-memory 3g --driver-memory 2g --driver-cores 1 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --numIterations 100 --storageLevel MEMORY_ONLY --stepSize 1.0 --regParam 0.01 hdfs://172.30.0.20:9000/HiBench/SVM/Input/large
25/10/01 09:48:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/10/01 09:48:42 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/10/01 09:48:44 INFO Configuration: resource-types.xml not found
25/10/01 09:48:44 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/10/01 09:48:44 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/10/01 09:48:44 INFO Client: Will allocate AM container, with 2432 MB memory including 384 MB overhead
25/10/01 09:48:44 INFO Client: Setting up container launch context for our AM
25/10/01 09:48:44 INFO Client: Setting up the launch environment for our AM container
25/10/01 09:48:44 INFO Client: Preparing resources for our AM container
25/10/01 09:48:44 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/10/01 09:48:46 INFO Client: Uploading resource file:/tmp/spark-1640ceab-64c8-457c-a4de-0e8e58b1ae0d/__spark_libs__8133291452081265883.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0059/__spark_libs__8133291452081265883.zip
25/10/01 09:48:47 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0059/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/10/01 09:48:51 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0059/sparkbench.conf
25/10/01 09:48:51 INFO Client: Uploading resource file:/tmp/spark-1640ceab-64c8-457c-a4de-0e8e58b1ae0d/__spark_conf__1341276331957270343.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0059/__spark_conf__.zip
25/10/01 09:48:52 INFO SecurityManager: Changing view acls to: sparker
25/10/01 09:48:52 INFO SecurityManager: Changing modify acls to: sparker
25/10/01 09:48:52 INFO SecurityManager: Changing view acls groups to:
25/10/01 09:48:52 INFO SecurityManager: Changing modify acls groups to:
25/10/01 09:48:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/10/01 09:48:52 INFO Client: Submitting application application_1759095470586_0059 to ResourceManager
25/10/01 09:48:52 INFO YarnClientImpl: Submitted application application_1759095470586_0059

=================================================================
Detected application_1759095470586_0059
=================================================================

25/10/01 09:48:53 INFO Client: Application report for application_1759095470586_0059 (state: ACCEPTED)
25/10/01 09:48:53 INFO Client:
	 client token: N/A
	 diagnostics: [Wed Oct 01 09:48:52 +0000 2025] Scheduler has assigned a container for AM, waiting for AM container to be launched
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1759312132311
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0059/
	 user: sparker
25/10/01 09:48:54 INFO Client: Application report for application_1759095470586_0059 (state: ACCEPTED)
25/10/01 09:48:55 INFO Client: Application report for application_1759095470586_0059 (state: ACCEPTED)
25/10/01 09:48:56 INFO Client: Application report for application_1759095470586_0059 (state: ACCEPTED)
25/10/01 09:48:57 INFO Client: Application report for application_1759095470586_0059 (state: ACCEPTED)
25/10/01 09:48:58 INFO Client: Application report for application_1759095470586_0059 (state: ACCEPTED)
25/10/01 09:48:59 INFO Client: Application report for application_1759095470586_0059 (state: ACCEPTED)
25/10/01 09:49:00 INFO Client: Application report for application_1759095470586_0059 (state: ACCEPTED)
25/10/01 09:49:01 INFO Client: Application report for application_1759095470586_0059 (state: ACCEPTED)
25/10/01 09:49:02 INFO Client: Application report for application_1759095470586_0059 (state: ACCEPTED)
25/10/01 09:49:03 INFO Client: Application report for application_1759095470586_0059 (state: ACCEPTED)
25/10/01 09:49:04 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-2
	 ApplicationMaster RPC port: 43939
	 queue: default
	 start time: 1759312132311
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0059/
	 user: sparker
25/10/01 10:39:56 INFO Client: Application report for application_1759095470586_0059 (state: FINISHED)
25/10/01 10:39:56 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-2
	 ApplicationMaster RPC port: 43939
	 queue: default
	 start time: 1759312132311
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0059/
	 user: sparker
25/10/01 10:39:57 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1759095470586_0059 with large data and queued
=================================================================

25/10/01 10:39:57 INFO ShutdownHookManager: Deleting directory /tmp/spark-1640ceab-64c8-457c-a4de-0e8e58b1ae0d
25/10/01 10:39:57 INFO ShutdownHookManager: Deleting directory /tmp/spark-dd487c19-d623-4bbc-9fdb-cf30b86a1863
/home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1759095470586_0059
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1759095470586_0059.zip
====================================================================================================
Benchmark Name: svm
Time to create app instrumentation: 0.06 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.10 seconds
Time to create stages instrumentation: 1.27 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 45.25 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
56.063029
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
56.439600
====================================================================================================
SQL PLANS: 0 | JOBS: 107 | JOBS WITHOUT SQL PLAN: 107 | STAGES: 210 | STAGES SKIPPED: 1 | TASK: 32865 TASK_WITH_ERRORS: 0 |
Get distributions elapsed_time: 0.155890 seconds
Starting parallel processing.
Time taken for parallel processing: 0.08274555206298828 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
56.488198
====================================================================================================
Finished application vectorization for application_1759095470586_0059_svm_large
Saving optimized workload into MongoDB: {'_id': 'application_1759095470586_0059_svm_large', 'experiment_id': 'svm_q1_evaluation', 'experiment_iteration': 5, 'target_workload': {'id': 'application_1753112283118_0437_svm_large', 'execution_time': 2020, 'name': 'svm', 'input_data_size': 'large', 'configuration': {'driver_cores': 1, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 5, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 200, 'task_cpus': 1}}, 'objective_function_real': 3053.9999999999986, 'acquisition_function_score': 3370.4, 'resource_usage_value': 20.0, 'execution_time': 3054, 'configuration': {'driver_cores': 1, 'driver_memory': 2, 'executor_cores': 2, 'executor_instances': 3, 'executor_memory': 3, 'sql_shuffle_partitions': 250, 'task_cpus': 1}, 'execution_time_error': 316, 'objective_function_predict': 3370.4000000000015, 'beta': None, 'alpha': None, 'repeated_config': None, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1759095470586_0059_svm_large documents into MongoDB

======================================================================================================================================================
[YORO/SBO] Evaluated (success #5):
    T_real=3054.00 | T_pred=3370.40 | OF_real=3054.00
    cfg=[  1   2   2   3   3 250   1]
======================================================================================================================================================

[YORO/SBO] Iter 6: T_pred=3426.95 | cfg=[  1   2   4   2   2 150   1]
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: yoro_bo_baseline, config: driver_cores=1 driver_memory=2 executor_cores=4 executor_instances=2 executor_memory=2 sql_shuffle_partitions=150 task_cpus=1
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/svm/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
patching args=
start SVM bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.SVMWithSGDExample           --master yarn --num-executors 2 --executor-cores 4 --executor-memory 2g --driver-memory 2g --driver-cores 1 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --numIterations 100 --storageLevel MEMORY_ONLY --stepSize 1.0 --regParam 0.01 hdfs://172.30.0.20:9000/HiBench/SVM/Input/large
25/10/01 10:41:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/10/01 10:41:11 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/10/01 10:41:12 INFO Configuration: resource-types.xml not found
25/10/01 10:41:12 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/10/01 10:41:12 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/10/01 10:41:12 INFO Client: Will allocate AM container, with 2432 MB memory including 384 MB overhead
25/10/01 10:41:12 INFO Client: Setting up container launch context for our AM
25/10/01 10:41:12 INFO Client: Setting up the launch environment for our AM container
25/10/01 10:41:12 INFO Client: Preparing resources for our AM container
25/10/01 10:41:12 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/10/01 10:41:13 INFO Client: Uploading resource file:/tmp/spark-9797f8c6-c3cc-42a6-8e92-f04da8137eda/__spark_libs__8704858292860901521.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0060/__spark_libs__8704858292860901521.zip
25/10/01 10:41:15 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0060/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/10/01 10:41:18 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0060/sparkbench.conf
25/10/01 10:41:18 INFO Client: Uploading resource file:/tmp/spark-9797f8c6-c3cc-42a6-8e92-f04da8137eda/__spark_conf__2245783555420229499.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0060/__spark_conf__.zip
25/10/01 10:41:19 INFO SecurityManager: Changing view acls to: sparker
25/10/01 10:41:19 INFO SecurityManager: Changing modify acls to: sparker
25/10/01 10:41:19 INFO SecurityManager: Changing view acls groups to:
25/10/01 10:41:19 INFO SecurityManager: Changing modify acls groups to:
25/10/01 10:41:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/10/01 10:41:19 INFO Client: Submitting application application_1759095470586_0060 to ResourceManager
25/10/01 10:41:19 INFO YarnClientImpl: Submitted application application_1759095470586_0060

=================================================================
Detected application_1759095470586_0060
=================================================================

25/10/01 10:41:20 INFO Client: Application report for application_1759095470586_0060 (state: ACCEPTED)
25/10/01 10:41:20 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1759315279598
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0060/
	 user: sparker
25/10/01 10:41:21 INFO Client: Application report for application_1759095470586_0060 (state: ACCEPTED)
25/10/01 10:41:22 INFO Client: Application report for application_1759095470586_0060 (state: ACCEPTED)
25/10/01 10:41:23 INFO Client: Application report for application_1759095470586_0060 (state: ACCEPTED)
25/10/01 10:41:24 INFO Client: Application report for application_1759095470586_0060 (state: ACCEPTED)
25/10/01 10:41:25 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-3
	 ApplicationMaster RPC port: 40685
	 queue: default
	 start time: 1759315279598
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0060/
	 user: sparker
25/10/01 11:30:13 INFO Client: Application report for application_1759095470586_0060 (state: FINISHED)
25/10/01 11:30:13 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-3
	 ApplicationMaster RPC port: 40685
	 queue: default
	 start time: 1759315279598
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0060/
	 user: sparker
25/10/01 11:30:14 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1759095470586_0060 with large data and queued
=================================================================

25/10/01 11:30:14 INFO ShutdownHookManager: Deleting directory /tmp/spark-7c29ae45-a608-47a3-a579-1f8bdf1284d8
25/10/01 11:30:14 INFO ShutdownHookManager: Deleting directory /tmp/spark-9797f8c6-c3cc-42a6-8e92-f04da8137eda
/home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1759095470586_0060
Failed to download Spark logs, we'll retry in next iteration 1: 500 Server Error: Server Error for url: http://localhost:18080/api/v1/applications/application_1759095470586_0060/logs
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1759095470586_0060.zip
====================================================================================================
Benchmark Name: svm
Time to create app instrumentation: 0.07 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.13 seconds
Time to create stages instrumentation: 1.10 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 42.82 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
50.421035
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
50.733764
====================================================================================================
SQL PLANS: 0 | JOBS: 107 | JOBS WITHOUT SQL PLAN: 107 | STAGES: 210 | STAGES SKIPPED: 1 | TASK: 32881 TASK_WITH_ERRORS: 0 |
Get distributions elapsed_time: 0.155001 seconds
Starting parallel processing.
Time taken for parallel processing: 0.0792546272277832 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
50.813418
====================================================================================================
Finished application vectorization for application_1759095470586_0060_svm_large
Saving optimized workload into MongoDB: {'_id': 'application_1759095470586_0060_svm_large', 'experiment_id': 'svm_q1_evaluation', 'experiment_iteration': 6, 'target_workload': {'id': 'application_1753112283118_0437_svm_large', 'execution_time': 2020, 'name': 'svm', 'input_data_size': 'large', 'configuration': {'driver_cores': 1, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 5, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 200, 'task_cpus': 1}}, 'objective_function_real': 2928.999999999999, 'acquisition_function_score': 3426.95, 'resource_usage_value': 18.0, 'execution_time': 2929, 'configuration': {'driver_cores': 1, 'driver_memory': 2, 'executor_cores': 4, 'executor_instances': 2, 'executor_memory': 2, 'sql_shuffle_partitions': 150, 'task_cpus': 1}, 'execution_time_error': 497, 'objective_function_predict': 3426.949999999997, 'beta': None, 'alpha': None, 'repeated_config': None, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1759095470586_0060_svm_large documents into MongoDB

======================================================================================================================================================
[YORO/SBO] Evaluated (success #6):
    T_real=2929.00 | T_pred=3426.95 | OF_real=2929.00
    cfg=[  1   2   4   2   2 150   1]
======================================================================================================================================================

[YORO/SBO] Iter 7: T_pred=3433.25 | cfg=[  1   2   1   4   4 200   1]
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: yoro_bo_baseline, config: driver_cores=1 driver_memory=2 executor_cores=1 executor_instances=4 executor_memory=4 sql_shuffle_partitions=200 task_cpus=1
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/svm/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
patching args=
start SVM bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.SVMWithSGDExample           --master yarn --num-executors 4 --executor-cores 1 --executor-memory 4g --driver-memory 2g --driver-cores 1 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --numIterations 100 --storageLevel MEMORY_ONLY --stepSize 1.0 --regParam 0.01 hdfs://172.30.0.20:9000/HiBench/SVM/Input/large
25/10/01 11:31:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/10/01 11:31:42 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/10/01 11:31:43 INFO Configuration: resource-types.xml not found
25/10/01 11:31:43 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/10/01 11:31:43 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/10/01 11:31:43 INFO Client: Will allocate AM container, with 2432 MB memory including 384 MB overhead
25/10/01 11:31:43 INFO Client: Setting up container launch context for our AM
25/10/01 11:31:43 INFO Client: Setting up the launch environment for our AM container
25/10/01 11:31:43 INFO Client: Preparing resources for our AM container
25/10/01 11:31:43 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/10/01 11:31:45 INFO Client: Uploading resource file:/tmp/spark-55234a26-a3c6-44e0-99f7-5cb6331ac5b9/__spark_libs__8316992578567097905.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0061/__spark_libs__8316992578567097905.zip
25/10/01 11:31:46 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0061/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/10/01 11:31:48 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0061/sparkbench.conf
25/10/01 11:31:48 INFO Client: Uploading resource file:/tmp/spark-55234a26-a3c6-44e0-99f7-5cb6331ac5b9/__spark_conf__615556738025746427.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0061/__spark_conf__.zip
25/10/01 11:31:49 INFO SecurityManager: Changing view acls to: sparker
25/10/01 11:31:49 INFO SecurityManager: Changing modify acls to: sparker
25/10/01 11:31:49 INFO SecurityManager: Changing view acls groups to:
25/10/01 11:31:49 INFO SecurityManager: Changing modify acls groups to:
25/10/01 11:31:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/10/01 11:31:49 INFO Client: Submitting application application_1759095470586_0061 to ResourceManager
25/10/01 11:31:49 INFO YarnClientImpl: Submitted application application_1759095470586_0061

=================================================================
Detected application_1759095470586_0061
=================================================================

25/10/01 11:31:50 INFO Client: Application report for application_1759095470586_0061 (state: ACCEPTED)
25/10/01 11:31:50 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1759318309200
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0061/
	 user: sparker
25/10/01 11:31:51 INFO Client: Application report for application_1759095470586_0061 (state: ACCEPTED)
25/10/01 11:31:52 INFO Client: Application report for application_1759095470586_0061 (state: ACCEPTED)
25/10/01 11:31:53 INFO Client: Application report for application_1759095470586_0061 (state: ACCEPTED)
25/10/01 11:31:54 INFO Client: Application report for application_1759095470586_0061 (state: ACCEPTED)
25/10/01 11:31:55 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-3
	 ApplicationMaster RPC port: 43041
	 queue: default
	 start time: 1759318309200
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0061/
	 user: sparker
25/10/01 12:23:43 INFO Client: Application report for application_1759095470586_0061 (state: FINISHED)
25/10/01 12:23:43 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-3
	 ApplicationMaster RPC port: 43041
	 queue: default
	 start time: 1759318309200
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0061/
	 user: sparker
25/10/01 12:23:44 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1759095470586_0061 with large data and queued
=================================================================

25/10/01 12:23:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-55234a26-a3c6-44e0-99f7-5cb6331ac5b9
25/10/01 12:23:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-5372ab43-d56b-4583-8dd2-1b27d6414d3f
/home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1759095470586_0061
Failed to download Spark logs, we'll retry in next iteration 1: 500 Server Error: Server Error for url: http://localhost:18080/api/v1/applications/application_1759095470586_0061/logs
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1759095470586_0061.zip
====================================================================================================
Benchmark Name: svm
Time to create app instrumentation: 0.08 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.15 seconds
Time to create stages instrumentation: 1.32 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 46.78 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
54.873876
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
55.166549
====================================================================================================
SQL PLANS: 0 | JOBS: 107 | JOBS WITHOUT SQL PLAN: 107 | STAGES: 210 | STAGES SKIPPED: 1 | TASK: 32849 TASK_WITH_ERRORS: 0 |
Get distributions elapsed_time: 0.137244 seconds
Starting parallel processing.
Time taken for parallel processing: 0.10967874526977539 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
55.282156
====================================================================================================
Finished application vectorization for application_1759095470586_0061_svm_large
Saving optimized workload into MongoDB: {'_id': 'application_1759095470586_0061_svm_large', 'experiment_id': 'svm_q1_evaluation', 'experiment_iteration': 7, 'target_workload': {'id': 'application_1753112283118_0437_svm_large', 'execution_time': 2020, 'name': 'svm', 'input_data_size': 'large', 'configuration': {'driver_cores': 1, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 5, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 200, 'task_cpus': 1}}, 'objective_function_real': 3109.0, 'acquisition_function_score': 3433.25, 'resource_usage_value': 18.0, 'execution_time': 3109, 'configuration': {'driver_cores': 1, 'driver_memory': 2, 'executor_cores': 1, 'executor_instances': 4, 'executor_memory': 4, 'sql_shuffle_partitions': 200, 'task_cpus': 1}, 'execution_time_error': 324, 'objective_function_predict': 3433.2500000000023, 'beta': None, 'alpha': None, 'repeated_config': None, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1759095470586_0061_svm_large documents into MongoDB

======================================================================================================================================================
[YORO/SBO] Evaluated (success #7):
    T_real=3109.00 | T_pred=3433.25 | OF_real=3109.00
    cfg=[  1   2   1   4   4 200   1]
======================================================================================================================================================

[YORO/SBO] Iter 8: T_pred=3442.44 | cfg=[  1   2   1   1   5 300   1]
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: yoro_bo_baseline, config: driver_cores=1 driver_memory=2 executor_cores=1 executor_instances=1 executor_memory=5 sql_shuffle_partitions=300 task_cpus=1
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/svm/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
patching args=
start SVM bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.SVMWithSGDExample           --master yarn --num-executors 1 --executor-cores 1 --executor-memory 5g --driver-memory 2g --driver-cores 1 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --numIterations 100 --storageLevel MEMORY_ONLY --stepSize 1.0 --regParam 0.01 hdfs://172.30.0.20:9000/HiBench/SVM/Input/large
25/10/01 12:25:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/10/01 12:25:17 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/10/01 12:25:18 INFO Configuration: resource-types.xml not found
25/10/01 12:25:18 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/10/01 12:25:18 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/10/01 12:25:18 INFO Client: Will allocate AM container, with 2432 MB memory including 384 MB overhead
25/10/01 12:25:18 INFO Client: Setting up container launch context for our AM
25/10/01 12:25:18 INFO Client: Setting up the launch environment for our AM container
25/10/01 12:25:18 INFO Client: Preparing resources for our AM container
25/10/01 12:25:18 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/10/01 12:25:19 INFO Client: Uploading resource file:/tmp/spark-6cf1bd05-2be1-4426-9f1e-bde3ed2cd0cc/__spark_libs__634136134050728146.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0062/__spark_libs__634136134050728146.zip
25/10/01 12:25:20 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0062/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/10/01 12:25:24 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0062/sparkbench.conf
25/10/01 12:25:25 INFO Client: Uploading resource file:/tmp/spark-6cf1bd05-2be1-4426-9f1e-bde3ed2cd0cc/__spark_conf__8189127893583908657.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0062/__spark_conf__.zip
25/10/01 12:25:25 INFO SecurityManager: Changing view acls to: sparker
25/10/01 12:25:25 INFO SecurityManager: Changing modify acls to: sparker
25/10/01 12:25:25 INFO SecurityManager: Changing view acls groups to:
25/10/01 12:25:25 INFO SecurityManager: Changing modify acls groups to:
25/10/01 12:25:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/10/01 12:25:25 INFO Client: Submitting application application_1759095470586_0062 to ResourceManager
25/10/01 12:25:25 INFO YarnClientImpl: Submitted application application_1759095470586_0062

=================================================================
Detected application_1759095470586_0062
=================================================================

25/10/01 12:25:26 INFO Client: Application report for application_1759095470586_0062 (state: ACCEPTED)
25/10/01 12:25:26 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1759321525268
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0062/
	 user: sparker
25/10/01 12:25:27 INFO Client: Application report for application_1759095470586_0062 (state: ACCEPTED)
25/10/01 12:25:28 INFO Client: Application report for application_1759095470586_0062 (state: ACCEPTED)
25/10/01 12:25:29 INFO Client: Application report for application_1759095470586_0062 (state: ACCEPTED)
25/10/01 12:25:30 INFO Client: Application report for application_1759095470586_0062 (state: ACCEPTED)
25/10/01 12:25:31 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-1
	 ApplicationMaster RPC port: 39119
	 queue: default
	 start time: 1759321525268
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0062/
	 user: sparker
25/10/01 15:42:50 INFO Client: Application report for application_1759095470586_0062 (state: FINISHED)
25/10/01 15:42:50 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-1
	 ApplicationMaster RPC port: 39119
	 queue: default
	 start time: 1759321525268
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0062/
	 user: sparker
25/10/01 15:42:51 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1759095470586_0062 with large data and queued
=================================================================

25/10/01 15:42:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-6cf1bd05-2be1-4426-9f1e-bde3ed2cd0cc
25/10/01 15:42:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-8da07026-c156-4023-af20-c2e719123f14
/home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1759095470586_0062
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1759095470586_0062.zip
====================================================================================================
Benchmark Name: svm
Time to create app instrumentation: 0.06 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.16 seconds
Time to create stages instrumentation: 1.19 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 45.22 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
56.824381
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
57.175552
====================================================================================================
SQL PLANS: 0 | JOBS: 107 | JOBS WITHOUT SQL PLAN: 107 | STAGES: 210 | STAGES SKIPPED: 1 | TASK: 32825 TASK_WITH_ERRORS: 0 |
Get distributions elapsed_time: 0.152184 seconds
Starting parallel processing.
Time taken for parallel processing: 0.09357953071594238 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
57.266611
====================================================================================================
Finished application vectorization for application_1759095470586_0062_svm_large
Saving optimized workload into MongoDB: {'_id': 'application_1759095470586_0062_svm_large', 'experiment_id': 'svm_q1_evaluation', 'experiment_iteration': 8, 'target_workload': {'id': 'application_1753112283118_0437_svm_large', 'execution_time': 2020, 'name': 'svm', 'input_data_size': 'large', 'configuration': {'driver_cores': 1, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 5, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 200, 'task_cpus': 1}}, 'objective_function_real': 11839.999999999989, 'acquisition_function_score': 3442.44, 'resource_usage_value': 7.0, 'execution_time': 11840, 'configuration': {'driver_cores': 1, 'driver_memory': 2, 'executor_cores': 1, 'executor_instances': 1, 'executor_memory': 5, 'sql_shuffle_partitions': 300, 'task_cpus': 1}, 'execution_time_error': 8398, 'objective_function_predict': 3442.4399999999973, 'beta': None, 'alpha': None, 'repeated_config': None, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1759095470586_0062_svm_large documents into MongoDB

======================================================================================================================================================
[YORO/SBO] Evaluated (success #8):
    T_real=11840.00 | T_pred=3442.44 | OF_real=11840.00
    cfg=[  1   2   1   1   5 300   1]
======================================================================================================================================================

[YORO/SBO] Iter 9: T_pred=3531.69 | cfg=[  2   3   3   3   3 200   1]
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: yoro_bo_baseline, config: driver_cores=2 driver_memory=3 executor_cores=3 executor_instances=3 executor_memory=3 sql_shuffle_partitions=200 task_cpus=1
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/svm/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
patching args=
start SVM bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.SVMWithSGDExample           --master yarn --num-executors 3 --executor-cores 3 --executor-memory 3g --driver-memory 3g --driver-cores 2 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --numIterations 100 --storageLevel MEMORY_ONLY --stepSize 1.0 --regParam 0.01 hdfs://172.30.0.20:9000/HiBench/SVM/Input/large
25/10/01 15:44:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/10/01 15:44:05 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/10/01 15:44:06 INFO Configuration: resource-types.xml not found
25/10/01 15:44:06 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/10/01 15:44:06 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/10/01 15:44:06 INFO Client: Will allocate AM container, with 3456 MB memory including 384 MB overhead
25/10/01 15:44:06 INFO Client: Setting up container launch context for our AM
25/10/01 15:44:06 INFO Client: Setting up the launch environment for our AM container
25/10/01 15:44:06 INFO Client: Preparing resources for our AM container
25/10/01 15:44:06 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/10/01 15:44:07 INFO Client: Uploading resource file:/tmp/spark-c4c67a68-94b7-4009-87a4-ca42cd5a8142/__spark_libs__5336417702732778501.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0063/__spark_libs__5336417702732778501.zip
25/10/01 15:44:08 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0063/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/10/01 15:44:11 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0063/sparkbench.conf
25/10/01 15:44:12 INFO Client: Uploading resource file:/tmp/spark-c4c67a68-94b7-4009-87a4-ca42cd5a8142/__spark_conf__3069742844909682194.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0063/__spark_conf__.zip
25/10/01 15:44:13 INFO SecurityManager: Changing view acls to: sparker
25/10/01 15:44:13 INFO SecurityManager: Changing modify acls to: sparker
25/10/01 15:44:13 INFO SecurityManager: Changing view acls groups to:
25/10/01 15:44:13 INFO SecurityManager: Changing modify acls groups to:
25/10/01 15:44:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/10/01 15:44:13 INFO Client: Submitting application application_1759095470586_0063 to ResourceManager
25/10/01 15:44:13 INFO YarnClientImpl: Submitted application application_1759095470586_0063

=================================================================
Detected application_1759095470586_0063
=================================================================

25/10/01 15:44:14 INFO Client: Application report for application_1759095470586_0063 (state: ACCEPTED)
25/10/01 15:44:14 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1759333453171
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0063/
	 user: sparker
25/10/01 15:44:15 INFO Client: Application report for application_1759095470586_0063 (state: ACCEPTED)
25/10/01 15:44:16 INFO Client: Application report for application_1759095470586_0063 (state: ACCEPTED)
25/10/01 15:44:17 INFO Client: Application report for application_1759095470586_0063 (state: ACCEPTED)
25/10/01 15:44:18 INFO Client: Application report for application_1759095470586_0063 (state: ACCEPTED)
25/10/01 15:44:19 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-3
	 ApplicationMaster RPC port: 37419
	 queue: default
	 start time: 1759333453171
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0063/
	 user: sparker
25/10/01 16:20:57 INFO Client: Application report for application_1759095470586_0063 (state: FINISHED)
25/10/01 16:20:57 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-3
	 ApplicationMaster RPC port: 37419
	 queue: default
	 start time: 1759333453171
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0063/
	 user: sparker
25/10/01 16:20:57 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1759095470586_0063 with large data and queued
=================================================================

25/10/01 16:20:57 INFO ShutdownHookManager: Deleting directory /tmp/spark-c4c67a68-94b7-4009-87a4-ca42cd5a8142
25/10/01 16:20:57 INFO ShutdownHookManager: Deleting directory /tmp/spark-d687578d-14a5-49ec-9d11-00c1d1b665b5
/home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1759095470586_0063
Failed to download Spark logs, we'll retry in next iteration 1: 500 Server Error: Server Error for url: http://localhost:18080/api/v1/applications/application_1759095470586_0063/logs
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1759095470586_0063.zip
====================================================================================================
Benchmark Name: svm
Time to create app instrumentation: 0.03 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.07 seconds
Time to create stages instrumentation: 0.57 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 21.93 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
26.983414
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
27.144525
====================================================================================================
SQL PLANS: 0 | JOBS: 107 | JOBS WITHOUT SQL PLAN: 107 | STAGES: 210 | STAGES SKIPPED: 1 | TASK: 32889 TASK_WITH_ERRORS: 0 |
Get distributions elapsed_time: 0.037492 seconds
Starting parallel processing.
Time taken for parallel processing: 0.04569363594055176 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
27.177383
====================================================================================================
Finished application vectorization for application_1759095470586_0063_svm_large
Saving optimized workload into MongoDB: {'_id': 'application_1759095470586_0063_svm_large', 'experiment_id': 'svm_q1_evaluation', 'experiment_iteration': 9, 'target_workload': {'id': 'application_1753112283118_0437_svm_large', 'execution_time': 2020, 'name': 'svm', 'input_data_size': 'large', 'configuration': {'driver_cores': 1, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 5, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 200, 'task_cpus': 1}}, 'objective_function_real': 2198.0, 'acquisition_function_score': 3531.69, 'resource_usage_value': 33.0, 'execution_time': 2198, 'configuration': {'driver_cores': 2, 'driver_memory': 3, 'executor_cores': 3, 'executor_instances': 3, 'executor_memory': 3, 'sql_shuffle_partitions': 200, 'task_cpus': 1}, 'execution_time_error': 1333, 'objective_function_predict': 3531.6899999999982, 'beta': None, 'alpha': None, 'repeated_config': None, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1759095470586_0063_svm_large documents into MongoDB

======================================================================================================================================================
[YORO/SBO] Evaluated (success #9):
    T_real=2198.00 | T_pred=3531.69 | OF_real=2198.00
    cfg=[  2   3   3   3   3 200   1]
======================================================================================================================================================

[YORO/SBO] Iter 10: T_pred=3603.67 | cfg=[  2   2   2   1   2 200   2]
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: yoro_bo_baseline, config: driver_cores=2 driver_memory=2 executor_cores=2 executor_instances=1 executor_memory=2 sql_shuffle_partitions=200 task_cpus=2
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/svm/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
patching args=
start SVM bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.SVMWithSGDExample           --master yarn --num-executors 1 --executor-cores 2 --executor-memory 2g --driver-memory 2g --driver-cores 2 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --numIterations 100 --storageLevel MEMORY_ONLY --stepSize 1.0 --regParam 0.01 hdfs://172.30.0.20:9000/HiBench/SVM/Input/large
25/10/01 16:21:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/10/01 16:22:00 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/10/01 16:22:01 INFO Configuration: resource-types.xml not found
25/10/01 16:22:01 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/10/01 16:22:01 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/10/01 16:22:01 INFO Client: Will allocate AM container, with 2432 MB memory including 384 MB overhead
25/10/01 16:22:01 INFO Client: Setting up container launch context for our AM
25/10/01 16:22:01 INFO Client: Setting up the launch environment for our AM container
25/10/01 16:22:01 INFO Client: Preparing resources for our AM container
25/10/01 16:22:01 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/10/01 16:22:02 INFO Client: Uploading resource file:/tmp/spark-0d447bdb-ae52-4973-8b89-7ffaf815c096/__spark_libs__985585399762264487.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0064/__spark_libs__985585399762264487.zip
25/10/01 16:22:03 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0064/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/10/01 16:22:06 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/svm/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0064/sparkbench.conf
25/10/01 16:22:07 INFO Client: Uploading resource file:/tmp/spark-0d447bdb-ae52-4973-8b89-7ffaf815c096/__spark_conf__206089375438925396.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1759095470586_0064/__spark_conf__.zip
25/10/01 16:22:07 INFO SecurityManager: Changing view acls to: sparker
25/10/01 16:22:07 INFO SecurityManager: Changing modify acls to: sparker
25/10/01 16:22:07 INFO SecurityManager: Changing view acls groups to:
25/10/01 16:22:07 INFO SecurityManager: Changing modify acls groups to:
25/10/01 16:22:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/10/01 16:22:07 INFO Client: Submitting application application_1759095470586_0064 to ResourceManager
25/10/01 16:22:08 INFO YarnClientImpl: Submitted application application_1759095470586_0064

=================================================================
Detected application_1759095470586_0064
=================================================================

25/10/01 16:22:09 INFO Client: Application report for application_1759095470586_0064 (state: ACCEPTED)
25/10/01 16:22:09 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1759335727799
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0064/
	 user: sparker
25/10/01 16:22:10 INFO Client: Application report for application_1759095470586_0064 (state: ACCEPTED)
25/10/01 16:22:11 INFO Client: Application report for application_1759095470586_0064 (state: ACCEPTED)
25/10/01 16:22:12 INFO Client: Application report for application_1759095470586_0064 (state: ACCEPTED)
25/10/01 16:22:13 INFO Client: Application report for application_1759095470586_0064 (state: ACCEPTED)
25/10/01 16:22:14 INFO Client: Application report for application_1759095470586_0064 (state: ACCEPTED)
25/10/01 16:22:15 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-2
	 ApplicationMaster RPC port: 36563
	 queue: default
	 start time: 1759335727799
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0064/
	 user: sparker
25/10/01 19:15:35 INFO Client: Application report for application_1759095470586_0064 (state: FINISHED)
25/10/01 19:15:35 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-2
	 ApplicationMaster RPC port: 36563
	 queue: default
	 start time: 1759335727799
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1759095470586_0064/
	 user: sparker
25/10/01 19:15:36 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1759095470586_0064 with large data and queued
=================================================================

25/10/01 19:15:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-689b32b4-8f7e-4fb4-bf86-2b23c57902fa
25/10/01 19:15:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-0d447bdb-ae52-4973-8b89-7ffaf815c096
/home/sparker/shared/HiBench2/bin/workloads/ml/svm/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1759095470586_0064
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1759095470586_0064.zip
====================================================================================================
Benchmark Name: svm
Time to create app instrumentation: 0.04 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.08 seconds
Time to create stages instrumentation: 0.58 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 21.27 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
25.443821
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
25.606719
====================================================================================================
SQL PLANS: 0 | JOBS: 107 | JOBS WITHOUT SQL PLAN: 107 | STAGES: 210 | STAGES SKIPPED: 1 | TASK: 32833 TASK_WITH_ERRORS: 0 |
Get distributions elapsed_time: 0.051484 seconds
Starting parallel processing.
Time taken for parallel processing: 0.05298137664794922 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
25.664092
====================================================================================================
Finished application vectorization for application_1759095470586_0064_svm_large
Saving optimized workload into MongoDB: {'_id': 'application_1759095470586_0064_svm_large', 'experiment_id': 'svm_q1_evaluation', 'experiment_iteration': 10, 'target_workload': {'id': 'application_1753112283118_0437_svm_large', 'execution_time': 2020, 'name': 'svm', 'input_data_size': 'large', 'configuration': {'driver_cores': 1, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 5, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 200, 'task_cpus': 1}}, 'objective_function_real': 10401.999999999995, 'acquisition_function_score': 3603.67, 'resource_usage_value': 8.0, 'execution_time': 10402, 'configuration': {'driver_cores': 2, 'driver_memory': 2, 'executor_cores': 2, 'executor_instances': 1, 'executor_memory': 2, 'sql_shuffle_partitions': 200, 'task_cpus': 2}, 'execution_time_error': 6799, 'objective_function_predict': 3603.6700000000033, 'beta': None, 'alpha': None, 'repeated_config': None, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1759095470586_0064_svm_large documents into MongoDB

======================================================================================================================================================
[YORO/SBO] Evaluated (success #10):
    T_real=10402.00 | T_pred=3603.67 | OF_real=10402.00
    cfg=[  2   2   2   1   2 200   2]
======================================================================================================================================================


=== Metrics (10 iterations) — YORO/SBO ===
T best ↓   : 2198.00  (found at i=9)
T first ↓  : 4358.00
SU (%) ↑   : -8.81
TC ↓       : 47792.00
Hit@0.10 ↑ : 0.00
nAOCC ↓    : 1.1743

