Target workload: id='application_1753554264659_0011_linear_large' time_stamp=datetime.datetime(2025, 9, 27, 15, 59, 18, 204101) app_name='LinearRegressionWithElasticNet' app_benchmark_workload='linear' time_execution=2976 dataset_size=3438575452220.0 app_benchmark_data_size=<InputDataSizeType.LARGE: 'large'> environment=Environment(driver_cores=2, driver_memory_gb=2, dynamic_allocation=False, executor_cores=4, executor_instances=3, executor_memory_gb=3, sql_adaptive=False, sql_shuffle_partitions=250, task_cpus=1) time_resources=None vector_metrics_yoro=[11882.676118679008, 2083.0, 726909.0, 49180.61914662561, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5889890456364445, 0.0, 266.0, 3.1354209393574184, 0.3710335906867699, 0.0, 234.0, 2.1365485082992803, 140724.31177493028, 0.0, 9174715.0, 706286.2544265186, 0.0, 0.0, 0.0, 0.0, 88373.58797849549, 0.0, 7243235.0, 454575.1037612657, 0.9600226363232144, 0.0, 500.0, 5.172511428947438, 69497058.3334007, 0.0, 136833363.0, 31945288.67857234, 5.252233315817131, 1.0, 10960.0, 65.71280460373842, 2959337.8713771775, 1028300.0, 852417200.0, 8164929.967529242, 500.4644690569546, 1.0, 18211.0, 1061.3602586409154, 126666383.71599498, 1340100.0, 2326849300.0, 114674566.58221376, 108.65518008003558, 0.0, 17528.0, 824.9608028341252, 0.00537612676341, 0.0, 82.0, 0.4751557475427558, 0.6148187073042565, 0.0, 127.0, 4.888429629571535] vector_metrics_garralda=[-0.3073695128434724, 0.31056860940387193, 0.7470203938808158, 0.09123177703618962, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.028073415682450396, 0.04237019628770855, 0.47669791695755714, 0.197216261185581, 0.02214360034784164, -0.11417673291582006, 0.5462250332991211, 0.1767155219113939, -0.11780129417316136, 0.4493814275167383, 0.45554105010913526, 0.08698434347869373, 0.0, 0.0, 0.0, 0.0, -0.07977685414342103, 0.4500387073315837, 0.49437503234909497, 0.08798617171772496, -0.009198667165656808, -0.030725723552616838, 0.5175481237171582, 0.24042491113500447, -0.23139647498895746, 0.7310085373649886, 0.4563657997729553, 0.020848876298015167, -0.13742665016139044, -0.26915244831096463, 0.6930524187438527, 0.1390140049573007, -0.17074650130036328, -0.7419078745937377, 0.9367156737088826, 0.03173781577578041, 0.3116790632024182, 0.6295347457889177, 0.08310392093440701, 0.034221018961783506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.9306266940816676, 0.1974625132198909, 0.8202002267711496, 0.08758712727352864, -0.30165096941296193, -0.5927240300429534, 0.8832416430555804, 0.035126066376293195, 2.0676127895310743, -2.264344295830506, 0.7187826853680158, 0.05784672392774406, -0.30165096941296193, -0.5927240300429534, 0.8832416430555804, 0.035126066376293195, 1.5294272588801059, -1.3660985009969642, 0.5751976879154023, 0.09974962186803597, -0.4359868055065132, 0.8099105419636428, 0.22239461009751896, 0.155797974080876, 0.9539497145395821, -1.3592959498051496, 0.9271665423211284, 0.15052545339915918, -1.5201106245062352, 2.1193079891653714, 0.014904934730574486, 0.0928968077748512, -0.20175462582801446, -0.7698046756479913, 0.9534184695995799, 0.020302425049813874, 0.022333961861683252, -0.949155212514361, 0.937620467823423, 0.011255802515434217] resource_usage=None resource_shape=None
Workload reference type(workload_ref)=<class 'list'> | len(workload_ref[0])=76
[[11882.676118679008, 2083.0, 726909.0, 49180.61914662561, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5889890456364445, 0.0, 266.0, 3.1354209393574184, 0.3710335906867699, 0.0, 234.0, 2.1365485082992803, 140724.31177493028, 0.0, 9174715.0, 706286.2544265186, 0.0, 0.0, 0.0, 0.0, 88373.58797849549, 0.0, 7243235.0, 454575.1037612657, 0.9600226363232144, 0.0, 500.0, 5.172511428947438, 69497058.3334007, 0.0, 136833363.0, 31945288.67857234, 5.252233315817131, 1.0, 10960.0, 65.71280460373842, 2959337.8713771775, 1028300.0, 852417200.0, 8164929.967529242, 500.4644690569546, 1.0, 18211.0, 1061.3602586409154, 126666383.71599498, 1340100.0, 2326849300.0, 114674566.58221376, 108.65518008003558, 0.0, 17528.0, 824.9608028341252, 0.00537612676341, 0.0, 82.0, 0.4751557475427558, 0.6148187073042565, 0.0, 127.0, 4.888429629571535, 3202.4229431711137, 2, 2, 4, 3, 3, 250, 1]]
Workload sd setting reference: [[2, 2, 4, 3, 3, 250, 1]]
Workload execution time reference: [2976]
[Candidate Space] grid_size=10080, n_candidates=256 (n=2)
[Candidate Space]  Generated 256 candidates via Sobol.
Total characterized workloads: 760 *******
Workload reference type(workload_characterization_extended_features_v2)=<class 'list'> | len(workload_characterization_extended_features_v2[0])=76
[YORO/SBO] Selected 10 candidates via GP+EI over oracle.
cfg=[  2   2   3   2   2 100   1]
cfg=[ 3  2  2  3  2 50  1]
cfg=[ 3  3  4  2  2 50  1]
cfg=[  3   2   4   3   3 100   1]
cfg=[ 2  2  4  4  5 50  1]
cfg=[  1   2   1   1   5 300   1]
cfg=[  1   3   1   3   4 200   1]
cfg=[  3   4   5   2   5 300   1]
cfg=[  2   3   4   3   3 250   2]
cfg=[  1   2   2   2   5 100   2]
[YORO/SBO] Iter 1: T_pred=1927.04 | cfg=[  2   2   3   2   2 100   1]
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: yoro_bo_baseline, config: driver_cores=2 driver_memory=2 executor_cores=3 executor_instances=2 executor_memory=2 sql_shuffle_partitions=100 task_cpus=1
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/linear/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/linear/spark/run.sh
patching args=
start LinearRegression bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.LinearRegressionWithElasticNet           --master yarn --num-executors 2 --executor-cores 3 --executor-memory 2g --driver-memory 2g --driver-cores 2 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --regParam 0.3 --elasticNetParam 0.8 --maxIter 50 --tol 1E-6 hdfs://172.30.0.20:9000/HiBench/Linear/Input/large
25/09/27 16:00:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/09/27 16:00:27 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/09/27 16:00:28 INFO Configuration: resource-types.xml not found
25/09/27 16:00:28 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/09/27 16:00:28 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/09/27 16:00:28 INFO Client: Will allocate AM container, with 2432 MB memory including 384 MB overhead
25/09/27 16:00:28 INFO Client: Setting up container launch context for our AM
25/09/27 16:00:28 INFO Client: Setting up the launch environment for our AM container
25/09/27 16:00:28 INFO Client: Preparing resources for our AM container
25/09/27 16:00:28 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/09/27 16:00:29 INFO Client: Uploading resource file:/tmp/spark-18650e85-b015-4549-be2b-ea808e114804/__spark_libs__3628095507836171561.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0033/__spark_libs__3628095507836171561.zip
25/09/27 16:00:30 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0033/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/09/27 16:00:33 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0033/sparkbench.conf
25/09/27 16:00:33 INFO Client: Uploading resource file:/tmp/spark-18650e85-b015-4549-be2b-ea808e114804/__spark_conf__9108362000830101081.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0033/__spark_conf__.zip
25/09/27 16:00:33 INFO SecurityManager: Changing view acls to: sparker
25/09/27 16:00:33 INFO SecurityManager: Changing modify acls to: sparker
25/09/27 16:00:33 INFO SecurityManager: Changing view acls groups to:
25/09/27 16:00:33 INFO SecurityManager: Changing modify acls groups to:
25/09/27 16:00:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/09/27 16:00:34 INFO Client: Submitting application application_1758867966614_0033 to ResourceManager
25/09/27 16:00:34 INFO YarnClientImpl: Submitted application application_1758867966614_0033

=================================================================
Detected application_1758867966614_0033
=================================================================

25/09/27 16:00:35 INFO Client: Application report for application_1758867966614_0033 (state: ACCEPTED)
25/09/27 16:00:35 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1758988834081
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0033/
	 user: sparker
25/09/27 16:00:36 INFO Client: Application report for application_1758867966614_0033 (state: ACCEPTED)
25/09/27 16:00:37 INFO Client: Application report for application_1758867966614_0033 (state: ACCEPTED)
25/09/27 16:00:38 INFO Client: Application report for application_1758867966614_0033 (state: ACCEPTED)
25/09/27 16:00:39 INFO Client: Application report for application_1758867966614_0033 (state: ACCEPTED)
25/09/27 16:00:40 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-1
	 ApplicationMaster RPC port: 44667
	 queue: default
	 start time: 1758988834081
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0033/
	 user: sparker
25/09/27 16:28:02 INFO Client: Application report for application_1758867966614_0033 (state: FINISHED)
25/09/27 16:28:03 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-1
	 ApplicationMaster RPC port: 44667
	 queue: default
	 start time: 1758988834081
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0033/
	 user: sparker
25/09/27 16:28:03 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1758867966614_0033 with large data and queued
=================================================================

25/09/27 16:28:03 INFO ShutdownHookManager: Deleting directory /tmp/spark-18650e85-b015-4549-be2b-ea808e114804
25/09/27 16:28:03 INFO ShutdownHookManager: Deleting directory /tmp/spark-5e2b2218-09a7-4302-aea3-fc00ff0c8c1a
/home/sparker/shared/HiBench2/bin/workloads/ml/linear/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1758867966614_0033
Failed to download Spark logs, we'll retry in next iteration 1: 500 Server Error: Server Error for url: http://localhost:18080/api/v1/applications/application_1758867966614_0033/logs
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1758867966614_0033.zip
====================================================================================================
Benchmark Name: linear
Time to create app instrumentation: 0.05 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.07 seconds
Time to create stages instrumentation: 0.46 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 39.73 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
44.678614
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
44.898604
====================================================================================================
SQL PLANS: 4 | JOBS: 102 | JOBS WITHOUT SQL PLAN: 98 | STAGES: 201 | STAGES SKIPPED: 98 | TASK: 61756 TASK_WITH_ERRORS: 0 |
********************** Not in SqlPlanNodeNameType************
WholeStageCodegen (2)
********************************************************************
********************** Not in SqlPlanNodeNameType************
WholeStageCodegen (1)
********************************************************************
Get distributions elapsed_time: 0.076344 seconds
Starting parallel processing.
Time taken for parallel processing: 0.0949711799621582 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
45.007839
====================================================================================================
Finished application vectorization for application_1758867966614_0033_linear_large
Saving optimized workload into MongoDB: {'_id': 'application_1758867966614_0033_linear_large', 'experiment_id': 'linear_q2_evaluation', 'experiment_iteration': 1, 'target_workload': {'id': 'application_1753554264659_0011_linear_large', 'execution_time': 2976, 'name': 'linear', 'input_data_size': 'large', 'configuration': {'driver_cores': 2, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 4, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 250, 'task_cpus': 1}}, 'objective_function_real': 1645.0, 'acquisition_function_score': 1927.04, 'resource_usage_value': 16.0, 'execution_time': 1645, 'configuration': {'driver_cores': 2, 'driver_memory': 2, 'executor_cores': 3, 'executor_instances': 2, 'executor_memory': 2, 'sql_shuffle_partitions': 100, 'task_cpus': 1}, 'execution_time_error': 282, 'objective_function_predict': 1927.04, 'beta': None, 'alpha': None, 'repeated_config': None, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1758867966614_0033_linear_large documents into MongoDB

======================================================================================================================================================
[YORO/SBO] Evaluated (success #1):
    T_real=1645.00 | T_pred=1927.04 | OF_real=1645.00
    cfg=[  2   2   3   2   2 100   1]
======================================================================================================================================================

[YORO/SBO] Iter 2: T_pred=1927.04 | cfg=[ 3  2  2  3  2 50  1]
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: yoro_bo_baseline, config: driver_cores=3 driver_memory=2 executor_cores=2 executor_instances=3 executor_memory=2 sql_shuffle_partitions=50 task_cpus=1
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/linear/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/linear/spark/run.sh
patching args=
start LinearRegression bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.LinearRegressionWithElasticNet           --master yarn --num-executors 3 --executor-cores 2 --executor-memory 2g --driver-memory 2g --driver-cores 3 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --regParam 0.3 --elasticNetParam 0.8 --maxIter 50 --tol 1E-6 hdfs://172.30.0.20:9000/HiBench/Linear/Input/large
25/09/27 16:29:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/09/27 16:29:24 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/09/27 16:29:25 INFO Configuration: resource-types.xml not found
25/09/27 16:29:25 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/09/27 16:29:25 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/09/27 16:29:25 INFO Client: Will allocate AM container, with 2432 MB memory including 384 MB overhead
25/09/27 16:29:25 INFO Client: Setting up container launch context for our AM
25/09/27 16:29:25 INFO Client: Setting up the launch environment for our AM container
25/09/27 16:29:25 INFO Client: Preparing resources for our AM container
25/09/27 16:29:25 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/09/27 16:29:27 INFO Client: Uploading resource file:/tmp/spark-dfe91df2-72f0-4b90-846d-45aabd41a0a5/__spark_libs__918490696627376510.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0034/__spark_libs__918490696627376510.zip
25/09/27 16:29:28 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0034/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/09/27 16:29:31 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0034/sparkbench.conf
25/09/27 16:29:31 INFO Client: Uploading resource file:/tmp/spark-dfe91df2-72f0-4b90-846d-45aabd41a0a5/__spark_conf__2007209916538403916.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0034/__spark_conf__.zip
25/09/27 16:29:31 INFO SecurityManager: Changing view acls to: sparker
25/09/27 16:29:31 INFO SecurityManager: Changing modify acls to: sparker
25/09/27 16:29:31 INFO SecurityManager: Changing view acls groups to:
25/09/27 16:29:31 INFO SecurityManager: Changing modify acls groups to:
25/09/27 16:29:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/09/27 16:29:31 INFO Client: Submitting application application_1758867966614_0034 to ResourceManager
25/09/27 16:29:31 INFO YarnClientImpl: Submitted application application_1758867966614_0034

=================================================================
Detected application_1758867966614_0034
=================================================================

25/09/27 16:29:32 INFO Client: Application report for application_1758867966614_0034 (state: ACCEPTED)
25/09/27 16:29:32 INFO Client:
	 client token: N/A
	 diagnostics: [Sat Sep 27 16:29:32 +0000 2025] Scheduler has assigned a container for AM, waiting for AM container to be launched
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1758990571705
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0034/
	 user: sparker
25/09/27 16:29:33 INFO Client: Application report for application_1758867966614_0034 (state: ACCEPTED)
25/09/27 16:29:34 INFO Client: Application report for application_1758867966614_0034 (state: ACCEPTED)
25/09/27 16:29:35 INFO Client: Application report for application_1758867966614_0034 (state: ACCEPTED)
25/09/27 16:29:36 INFO Client: Application report for application_1758867966614_0034 (state: ACCEPTED)
25/09/27 16:29:37 INFO Client: Application report for application_1758867966614_0034 (state: ACCEPTED)
25/09/27 16:29:38 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-3
	 ApplicationMaster RPC port: 36653
	 queue: default
	 start time: 1758990571705
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0034/
	 user: sparker
25/09/27 17:11:13 INFO Client: Application report for application_1758867966614_0034 (state: FINISHED)
25/09/27 17:11:13 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-3
	 ApplicationMaster RPC port: 36653
	 queue: default
	 start time: 1758990571705
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0034/
	 user: sparker
25/09/27 17:11:13 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1758867966614_0034 with large data and queued
=================================================================

25/09/27 17:11:13 INFO ShutdownHookManager: Deleting directory /tmp/spark-31076e06-06f5-4919-9ac6-d639d5dd18ce
25/09/27 17:11:13 INFO ShutdownHookManager: Deleting directory /tmp/spark-dfe91df2-72f0-4b90-846d-45aabd41a0a5
/home/sparker/shared/HiBench2/bin/workloads/ml/linear/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1758867966614_0034
Failed to download Spark logs, we'll retry in next iteration 1: 500 Server Error: Server Error for url: http://localhost:18080/api/v1/applications/application_1758867966614_0034/logs
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1758867966614_0034.zip
====================================================================================================
Benchmark Name: linear
Time to create app instrumentation: 0.05 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.07 seconds
Time to create stages instrumentation: 0.47 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 39.27 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
44.963544
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
45.235699
====================================================================================================
SQL PLANS: 4 | JOBS: 102 | JOBS WITHOUT SQL PLAN: 98 | STAGES: 201 | STAGES SKIPPED: 98 | TASK: 61756 TASK_WITH_ERRORS: 0 |
********************** Not in SqlPlanNodeNameType************
WholeStageCodegen (2)
********************************************************************
********************** Not in SqlPlanNodeNameType************
WholeStageCodegen (1)
********************************************************************
Get distributions elapsed_time: 0.074892 seconds
Starting parallel processing.
Time taken for parallel processing: 0.09889078140258789 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
45.286120
====================================================================================================
Finished application vectorization for application_1758867966614_0034_linear_large
Saving optimized workload into MongoDB: {'_id': 'application_1758867966614_0034_linear_large', 'experiment_id': 'linear_q2_evaluation', 'experiment_iteration': 2, 'target_workload': {'id': 'application_1753554264659_0011_linear_large', 'execution_time': 2976, 'name': 'linear', 'input_data_size': 'large', 'configuration': {'driver_cores': 2, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 4, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 250, 'task_cpus': 1}}, 'objective_function_real': 2496.000000000001, 'acquisition_function_score': 1927.04, 'resource_usage_value': 18.0, 'execution_time': 2496, 'configuration': {'driver_cores': 3, 'driver_memory': 2, 'executor_cores': 2, 'executor_instances': 3, 'executor_memory': 2, 'sql_shuffle_partitions': 50, 'task_cpus': 1}, 'execution_time_error': 569, 'objective_function_predict': 1927.04, 'beta': None, 'alpha': None, 'repeated_config': None, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1758867966614_0034_linear_large documents into MongoDB

======================================================================================================================================================
[YORO/SBO] Evaluated (success #2):
    T_real=2496.00 | T_pred=1927.04 | OF_real=2496.00
    cfg=[ 3  2  2  3  2 50  1]
======================================================================================================================================================

[YORO/SBO] Iter 3: T_pred=1927.52 | cfg=[ 3  3  4  2  2 50  1]
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: yoro_bo_baseline, config: driver_cores=3 driver_memory=3 executor_cores=4 executor_instances=2 executor_memory=2 sql_shuffle_partitions=50 task_cpus=1
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/linear/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/linear/spark/run.sh
patching args=
start LinearRegression bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.LinearRegressionWithElasticNet           --master yarn --num-executors 2 --executor-cores 4 --executor-memory 2g --driver-memory 3g --driver-cores 3 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --regParam 0.3 --elasticNetParam 0.8 --maxIter 50 --tol 1E-6 hdfs://172.30.0.20:9000/HiBench/Linear/Input/large
25/09/27 17:12:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/09/27 17:12:36 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/09/27 17:12:37 INFO Configuration: resource-types.xml not found
25/09/27 17:12:37 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/09/27 17:12:37 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/09/27 17:12:37 INFO Client: Will allocate AM container, with 3456 MB memory including 384 MB overhead
25/09/27 17:12:37 INFO Client: Setting up container launch context for our AM
25/09/27 17:12:37 INFO Client: Setting up the launch environment for our AM container
25/09/27 17:12:37 INFO Client: Preparing resources for our AM container
25/09/27 17:12:37 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/09/27 17:12:38 INFO Client: Uploading resource file:/tmp/spark-7f7971aa-c375-4712-8049-8a3973752e63/__spark_libs__1298927431730342650.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0035/__spark_libs__1298927431730342650.zip
25/09/27 17:12:40 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0035/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/09/27 17:12:42 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0035/sparkbench.conf
25/09/27 17:12:42 INFO Client: Uploading resource file:/tmp/spark-7f7971aa-c375-4712-8049-8a3973752e63/__spark_conf__2852083131119553302.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0035/__spark_conf__.zip
25/09/27 17:12:42 INFO SecurityManager: Changing view acls to: sparker
25/09/27 17:12:42 INFO SecurityManager: Changing modify acls to: sparker
25/09/27 17:12:42 INFO SecurityManager: Changing view acls groups to:
25/09/27 17:12:42 INFO SecurityManager: Changing modify acls groups to:
25/09/27 17:12:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/09/27 17:12:42 INFO Client: Submitting application application_1758867966614_0035 to ResourceManager
25/09/27 17:12:42 INFO YarnClientImpl: Submitted application application_1758867966614_0035

=================================================================
Detected application_1758867966614_0035
=================================================================

25/09/27 17:12:43 INFO Client: Application report for application_1758867966614_0035 (state: ACCEPTED)
25/09/27 17:12:43 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1758993162476
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0035/
	 user: sparker
25/09/27 17:12:44 INFO Client: Application report for application_1758867966614_0035 (state: ACCEPTED)
25/09/27 17:12:45 INFO Client: Application report for application_1758867966614_0035 (state: ACCEPTED)
25/09/27 17:12:46 INFO Client: Application report for application_1758867966614_0035 (state: ACCEPTED)
25/09/27 17:12:47 INFO Client: Application report for application_1758867966614_0035 (state: ACCEPTED)
25/09/27 17:12:48 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-3
	 ApplicationMaster RPC port: 33377
	 queue: default
	 start time: 1758993162476
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0035/
	 user: sparker
25/09/27 17:58:44 INFO Client: Application report for application_1758867966614_0035 (state: FINISHED)
25/09/27 17:58:44 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-3
	 ApplicationMaster RPC port: 33377
	 queue: default
	 start time: 1758993162476
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0035/
	 user: sparker
25/09/27 17:58:44 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1758867966614_0035 with large data and queued
=================================================================

25/09/27 17:58:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-1e7eb12f-4a27-4a4f-974e-a241e6f816e8
25/09/27 17:58:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-7f7971aa-c375-4712-8049-8a3973752e63
/home/sparker/shared/HiBench2/bin/workloads/ml/linear/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1758867966614_0035
Failed to download Spark logs, we'll retry in next iteration 1: 500 Server Error: Server Error for url: http://localhost:18080/api/v1/applications/application_1758867966614_0035/logs
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1758867966614_0035.zip
====================================================================================================
Benchmark Name: linear
Time to create app instrumentation: 0.05 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.08 seconds
Time to create stages instrumentation: 0.48 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 40.36 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
46.532805
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
46.772108
====================================================================================================
SQL PLANS: 4 | JOBS: 102 | JOBS WITHOUT SQL PLAN: 98 | STAGES: 201 | STAGES SKIPPED: 98 | TASK: 61756 TASK_WITH_ERRORS: 0 |
********************** Not in SqlPlanNodeNameType************
WholeStageCodegen (2)
********************************************************************
********************** Not in SqlPlanNodeNameType************
WholeStageCodegen (1)
********************************************************************
Get distributions elapsed_time: 0.074858 seconds
Starting parallel processing.
Time taken for parallel processing: 0.09262871742248535 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
46.829608
====================================================================================================
Finished application vectorization for application_1758867966614_0035_linear_large
Saving optimized workload into MongoDB: {'_id': 'application_1758867966614_0035_linear_large', 'experiment_id': 'linear_q2_evaluation', 'experiment_iteration': 3, 'target_workload': {'id': 'application_1753554264659_0011_linear_large', 'execution_time': 2976, 'name': 'linear', 'input_data_size': 'large', 'configuration': {'driver_cores': 2, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 4, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 250, 'task_cpus': 1}}, 'objective_function_real': 2757.0000000000005, 'acquisition_function_score': 1927.52, 'resource_usage_value': 25.0, 'execution_time': 2757, 'configuration': {'driver_cores': 3, 'driver_memory': 3, 'executor_cores': 4, 'executor_instances': 2, 'executor_memory': 2, 'sql_shuffle_partitions': 50, 'task_cpus': 1}, 'execution_time_error': 830, 'objective_function_predict': 1927.5200000000007, 'beta': None, 'alpha': None, 'repeated_config': None, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1758867966614_0035_linear_large documents into MongoDB

======================================================================================================================================================
[YORO/SBO] Evaluated (success #3):
    T_real=2757.00 | T_pred=1927.52 | OF_real=2757.00
    cfg=[ 3  3  4  2  2 50  1]
======================================================================================================================================================

[YORO/SBO] Iter 4: T_pred=1927.52 | cfg=[  3   2   4   3   3 100   1]
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: yoro_bo_baseline, config: driver_cores=3 driver_memory=2 executor_cores=4 executor_instances=3 executor_memory=3 sql_shuffle_partitions=100 task_cpus=1
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/linear/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/linear/spark/run.sh
patching args=
start LinearRegression bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.LinearRegressionWithElasticNet           --master yarn --num-executors 3 --executor-cores 4 --executor-memory 3g --driver-memory 2g --driver-cores 3 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --regParam 0.3 --elasticNetParam 0.8 --maxIter 50 --tol 1E-6 hdfs://172.30.0.20:9000/HiBench/Linear/Input/large
25/09/27 18:00:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/09/27 18:00:08 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/09/27 18:00:09 INFO Configuration: resource-types.xml not found
25/09/27 18:00:09 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/09/27 18:00:09 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/09/27 18:00:09 INFO Client: Will allocate AM container, with 2432 MB memory including 384 MB overhead
25/09/27 18:00:09 INFO Client: Setting up container launch context for our AM
25/09/27 18:00:09 INFO Client: Setting up the launch environment for our AM container
25/09/27 18:00:09 INFO Client: Preparing resources for our AM container
25/09/27 18:00:09 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/09/27 18:00:10 INFO Client: Uploading resource file:/tmp/spark-9a2b02c4-ccb1-4526-b320-dabf8aac2f95/__spark_libs__4438991444595890159.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0036/__spark_libs__4438991444595890159.zip
25/09/27 18:00:11 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0036/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/09/27 18:00:13 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0036/sparkbench.conf
25/09/27 18:00:14 INFO Client: Uploading resource file:/tmp/spark-9a2b02c4-ccb1-4526-b320-dabf8aac2f95/__spark_conf__2117782866446916000.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0036/__spark_conf__.zip
25/09/27 18:00:14 INFO SecurityManager: Changing view acls to: sparker
25/09/27 18:00:14 INFO SecurityManager: Changing modify acls to: sparker
25/09/27 18:00:14 INFO SecurityManager: Changing view acls groups to:
25/09/27 18:00:14 INFO SecurityManager: Changing modify acls groups to:
25/09/27 18:00:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/09/27 18:00:14 INFO Client: Submitting application application_1758867966614_0036 to ResourceManager
25/09/27 18:00:14 INFO YarnClientImpl: Submitted application application_1758867966614_0036

=================================================================
Detected application_1758867966614_0036
=================================================================

25/09/27 18:00:15 INFO Client: Application report for application_1758867966614_0036 (state: ACCEPTED)
25/09/27 18:00:15 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1758996014384
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0036/
	 user: sparker
25/09/27 18:00:16 INFO Client: Application report for application_1758867966614_0036 (state: ACCEPTED)
25/09/27 18:00:17 INFO Client: Application report for application_1758867966614_0036 (state: ACCEPTED)
25/09/27 18:00:18 INFO Client: Application report for application_1758867966614_0036 (state: ACCEPTED)
25/09/27 18:00:19 INFO Client: Application report for application_1758867966614_0036 (state: ACCEPTED)
25/09/27 18:00:20 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-3
	 ApplicationMaster RPC port: 39925
	 queue: default
	 start time: 1758996014384
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0036/
	 user: sparker
25/09/27 18:46:37 INFO Client: Application report for application_1758867966614_0036 (state: FINISHED)
25/09/27 18:46:37 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-3
	 ApplicationMaster RPC port: 39925
	 queue: default
	 start time: 1758996014384
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0036/
	 user: sparker
25/09/27 18:46:37 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1758867966614_0036 with large data and queued
=================================================================

25/09/27 18:46:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-9a2b02c4-ccb1-4526-b320-dabf8aac2f95
25/09/27 18:46:37 INFO ShutdownHookManager: Deleting directory /tmp/spark-400b77a2-7b57-45c2-a34c-c693c63eabd9
/home/sparker/shared/HiBench2/bin/workloads/ml/linear/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1758867966614_0036
Failed to download Spark logs, we'll retry in next iteration 1: 500 Server Error: Server Error for url: http://localhost:18080/api/v1/applications/application_1758867966614_0036/logs
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1758867966614_0036.zip
====================================================================================================
Benchmark Name: linear
Time to create app instrumentation: 0.06 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.06 seconds
Time to create stages instrumentation: 0.43 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 40.36 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
46.017173
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
46.287255
====================================================================================================
SQL PLANS: 4 | JOBS: 102 | JOBS WITHOUT SQL PLAN: 98 | STAGES: 201 | STAGES SKIPPED: 98 | TASK: 61756 TASK_WITH_ERRORS: 0 |
********************** Not in SqlPlanNodeNameType************
WholeStageCodegen (2)
********************************************************************
********************** Not in SqlPlanNodeNameType************
WholeStageCodegen (1)
********************************************************************
Get distributions elapsed_time: 0.071947 seconds
Starting parallel processing.
Time taken for parallel processing: 0.08975744247436523 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
46.347384
====================================================================================================
Finished application vectorization for application_1758867966614_0036_linear_large
Saving optimized workload into MongoDB: {'_id': 'application_1758867966614_0036_linear_large', 'experiment_id': 'linear_q2_evaluation', 'experiment_iteration': 4, 'target_workload': {'id': 'application_1753554264659_0011_linear_large', 'execution_time': 2976, 'name': 'linear', 'input_data_size': 'large', 'configuration': {'driver_cores': 2, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 4, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 250, 'task_cpus': 1}}, 'objective_function_real': 2777.999999999999, 'acquisition_function_score': 1927.52, 'resource_usage_value': 42.0, 'execution_time': 2778, 'configuration': {'driver_cores': 3, 'driver_memory': 2, 'executor_cores': 4, 'executor_instances': 3, 'executor_memory': 3, 'sql_shuffle_partitions': 100, 'task_cpus': 1}, 'execution_time_error': 851, 'objective_function_predict': 1927.5200000000007, 'beta': None, 'alpha': None, 'repeated_config': None, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1758867966614_0036_linear_large documents into MongoDB

======================================================================================================================================================
[YORO/SBO] Evaluated (success #4):
    T_real=2778.00 | T_pred=1927.52 | OF_real=2778.00
    cfg=[  3   2   4   3   3 100   1]
======================================================================================================================================================

[YORO/SBO] Iter 5: T_pred=1927.72 | cfg=[ 2  2  4  4  5 50  1]
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: yoro_bo_baseline, config: driver_cores=2 driver_memory=2 executor_cores=4 executor_instances=4 executor_memory=5 sql_shuffle_partitions=50 task_cpus=1
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/linear/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/linear/spark/run.sh
patching args=
start LinearRegression bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.LinearRegressionWithElasticNet           --master yarn --num-executors 4 --executor-cores 4 --executor-memory 5g --driver-memory 2g --driver-cores 2 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --regParam 0.3 --elasticNetParam 0.8 --maxIter 50 --tol 1E-6 hdfs://172.30.0.20:9000/HiBench/Linear/Input/large
25/09/27 18:47:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/09/27 18:48:00 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/09/27 18:48:01 INFO Configuration: resource-types.xml not found
25/09/27 18:48:01 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/09/27 18:48:02 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/09/27 18:48:02 INFO Client: Will allocate AM container, with 2432 MB memory including 384 MB overhead
25/09/27 18:48:02 INFO Client: Setting up container launch context for our AM
25/09/27 18:48:02 INFO Client: Setting up the launch environment for our AM container
25/09/27 18:48:02 INFO Client: Preparing resources for our AM container
25/09/27 18:48:02 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/09/27 18:48:03 INFO Client: Uploading resource file:/tmp/spark-2910c828-d02d-48dd-9a2d-fa3fceb0c00b/__spark_libs__5404700971377147059.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0037/__spark_libs__5404700971377147059.zip
25/09/27 18:48:05 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0037/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/09/27 18:48:08 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0037/sparkbench.conf
25/09/27 18:48:08 INFO Client: Uploading resource file:/tmp/spark-2910c828-d02d-48dd-9a2d-fa3fceb0c00b/__spark_conf__2376915739450651583.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0037/__spark_conf__.zip
25/09/27 18:48:08 INFO SecurityManager: Changing view acls to: sparker
25/09/27 18:48:08 INFO SecurityManager: Changing modify acls to: sparker
25/09/27 18:48:08 INFO SecurityManager: Changing view acls groups to:
25/09/27 18:48:08 INFO SecurityManager: Changing modify acls groups to:
25/09/27 18:48:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/09/27 18:48:08 INFO Client: Submitting application application_1758867966614_0037 to ResourceManager
25/09/27 18:48:09 INFO YarnClientImpl: Submitted application application_1758867966614_0037

=================================================================
Detected application_1758867966614_0037
=================================================================

25/09/27 18:48:10 INFO Client: Application report for application_1758867966614_0037 (state: ACCEPTED)
25/09/27 18:48:10 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1758998888829
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0037/
	 user: sparker
25/09/27 18:48:11 INFO Client: Application report for application_1758867966614_0037 (state: ACCEPTED)
25/09/27 18:48:12 INFO Client: Application report for application_1758867966614_0037 (state: ACCEPTED)
25/09/27 18:48:13 INFO Client: Application report for application_1758867966614_0037 (state: ACCEPTED)
25/09/27 18:48:14 INFO Client: Application report for application_1758867966614_0037 (state: ACCEPTED)
25/09/27 18:48:15 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-3
	 ApplicationMaster RPC port: 45911
	 queue: default
	 start time: 1758998888829
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0037/
	 user: sparker
25/09/27 19:15:29 INFO Client: Application report for application_1758867966614_0037 (state: FINISHED)
25/09/27 19:15:29 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-3
	 ApplicationMaster RPC port: 45911
	 queue: default
	 start time: 1758998888829
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0037/
	 user: sparker
25/09/27 19:15:29 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1758867966614_0037 with large data and queued
=================================================================

25/09/27 19:15:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-12687667-f46c-4ad3-9b6c-298a39c2563c
25/09/27 19:15:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-2910c828-d02d-48dd-9a2d-fa3fceb0c00b
/home/sparker/shared/HiBench2/bin/workloads/ml/linear/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1758867966614_0037
Failed to download Spark logs, we'll retry in next iteration 1: 500 Server Error: Server Error for url: http://localhost:18080/api/v1/applications/application_1758867966614_0037/logs
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1758867966614_0037.zip
====================================================================================================
Benchmark Name: linear
Time to create app instrumentation: 0.06 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.07 seconds
Time to create stages instrumentation: 0.47 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 41.08 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
47.408095
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
47.679035
====================================================================================================
SQL PLANS: 4 | JOBS: 102 | JOBS WITHOUT SQL PLAN: 98 | STAGES: 201 | STAGES SKIPPED: 98 | TASK: 61756 TASK_WITH_ERRORS: 0 |
********************** Not in SqlPlanNodeNameType************
WholeStageCodegen (2)
********************************************************************
********************** Not in SqlPlanNodeNameType************
WholeStageCodegen (1)
********************************************************************
Get distributions elapsed_time: 0.075552 seconds
Starting parallel processing.
Time taken for parallel processing: 0.08976912498474121 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
47.752582
====================================================================================================
Finished application vectorization for application_1758867966614_0037_linear_large
Saving optimized workload into MongoDB: {'_id': 'application_1758867966614_0037_linear_large', 'experiment_id': 'linear_q2_evaluation', 'experiment_iteration': 5, 'target_workload': {'id': 'application_1753554264659_0011_linear_large', 'execution_time': 2976, 'name': 'linear', 'input_data_size': 'large', 'configuration': {'driver_cores': 2, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 4, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 250, 'task_cpus': 1}}, 'objective_function_real': 1634.9999999999995, 'acquisition_function_score': 1927.72, 'resource_usage_value': 84.0, 'execution_time': 1635, 'configuration': {'driver_cores': 2, 'driver_memory': 2, 'executor_cores': 4, 'executor_instances': 4, 'executor_memory': 5, 'sql_shuffle_partitions': 50, 'task_cpus': 1}, 'execution_time_error': 292, 'objective_function_predict': 1927.7200000000007, 'beta': None, 'alpha': None, 'repeated_config': None, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1758867966614_0037_linear_large documents into MongoDB

======================================================================================================================================================
[YORO/SBO] Evaluated (success #5):
    T_real=1635.00 | T_pred=1927.72 | OF_real=1635.00
    cfg=[ 2  2  4  4  5 50  1]
======================================================================================================================================================

[YORO/SBO] Iter 6: T_pred=1934.32 | cfg=[  1   2   1   1   5 300   1]
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: yoro_bo_baseline, config: driver_cores=1 driver_memory=2 executor_cores=1 executor_instances=1 executor_memory=5 sql_shuffle_partitions=300 task_cpus=1
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/linear/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/linear/spark/run.sh
patching args=
start LinearRegression bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.LinearRegressionWithElasticNet           --master yarn --num-executors 1 --executor-cores 1 --executor-memory 5g --driver-memory 2g --driver-cores 1 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --regParam 0.3 --elasticNetParam 0.8 --maxIter 50 --tol 1E-6 hdfs://172.30.0.20:9000/HiBench/Linear/Input/large
25/09/27 19:16:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/09/27 19:16:54 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/09/27 19:16:55 INFO Configuration: resource-types.xml not found
25/09/27 19:16:55 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/09/27 19:16:55 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/09/27 19:16:55 INFO Client: Will allocate AM container, with 2432 MB memory including 384 MB overhead
25/09/27 19:16:55 INFO Client: Setting up container launch context for our AM
25/09/27 19:16:55 INFO Client: Setting up the launch environment for our AM container
25/09/27 19:16:55 INFO Client: Preparing resources for our AM container
25/09/27 19:16:55 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/09/27 19:16:56 INFO Client: Uploading resource file:/tmp/spark-b8a4ad52-8573-4405-b7b7-5a60e49826c7/__spark_libs__3984617334837043639.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0038/__spark_libs__3984617334837043639.zip
25/09/27 19:16:57 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0038/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/09/27 19:17:00 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0038/sparkbench.conf
25/09/27 19:17:00 INFO Client: Uploading resource file:/tmp/spark-b8a4ad52-8573-4405-b7b7-5a60e49826c7/__spark_conf__6895068437481078212.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0038/__spark_conf__.zip
25/09/27 19:17:00 INFO SecurityManager: Changing view acls to: sparker
25/09/27 19:17:00 INFO SecurityManager: Changing modify acls to: sparker
25/09/27 19:17:00 INFO SecurityManager: Changing view acls groups to:
25/09/27 19:17:00 INFO SecurityManager: Changing modify acls groups to:
25/09/27 19:17:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/09/27 19:17:00 INFO Client: Submitting application application_1758867966614_0038 to ResourceManager
25/09/27 19:17:01 INFO YarnClientImpl: Submitted application application_1758867966614_0038

=================================================================
Detected application_1758867966614_0038
=================================================================

25/09/27 19:17:02 INFO Client: Application report for application_1758867966614_0038 (state: ACCEPTED)
25/09/27 19:17:02 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1759000620947
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0038/
	 user: sparker
25/09/27 19:17:03 INFO Client: Application report for application_1758867966614_0038 (state: ACCEPTED)
25/09/27 19:17:04 INFO Client: Application report for application_1758867966614_0038 (state: ACCEPTED)
25/09/27 19:17:05 INFO Client: Application report for application_1758867966614_0038 (state: ACCEPTED)
25/09/27 19:17:06 INFO Client: Application report for application_1758867966614_0038 (state: ACCEPTED)
25/09/27 19:17:07 INFO Client: Application report for application_1758867966614_0038 (state: ACCEPTED)
25/09/27 19:17:08 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-1
	 ApplicationMaster RPC port: 35975
	 queue: default
	 start time: 1759000620947
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0038/
	 user: sparker
25/09/27 20:45:06 INFO Client: Application report for application_1758867966614_0038 (state: FINISHED)
25/09/27 20:45:06 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-1
	 ApplicationMaster RPC port: 35975
	 queue: default
	 start time: 1759000620947
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0038/
	 user: sparker
25/09/27 20:45:06 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1758867966614_0038 with large data and queued
=================================================================

25/09/27 20:45:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-b8a4ad52-8573-4405-b7b7-5a60e49826c7
25/09/27 20:45:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-22ee4ab0-5c64-4365-ac94-445bc70497d3
/home/sparker/shared/HiBench2/bin/workloads/ml/linear/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1758867966614_0038
Failed to download Spark logs, we'll retry in next iteration 1: 500 Server Error: Server Error for url: http://localhost:18080/api/v1/applications/application_1758867966614_0038/logs
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1758867966614_0038.zip
====================================================================================================
Benchmark Name: linear
Time to create app instrumentation: 0.06 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.07 seconds
Time to create stages instrumentation: 0.51 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 41.19 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
47.725590
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
47.959504
====================================================================================================
SQL PLANS: 4 | JOBS: 102 | JOBS WITHOUT SQL PLAN: 98 | STAGES: 201 | STAGES SKIPPED: 98 | TASK: 61756 TASK_WITH_ERRORS: 0 |
********************** Not in SqlPlanNodeNameType************
WholeStageCodegen (2)
********************************************************************
********************** Not in SqlPlanNodeNameType************
WholeStageCodegen (1)
********************************************************************
Get distributions elapsed_time: 0.070786 seconds
Starting parallel processing.
Time taken for parallel processing: 0.08708882331848145 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
48.024916
====================================================================================================
Finished application vectorization for application_1758867966614_0038_linear_large
Saving optimized workload into MongoDB: {'_id': 'application_1758867966614_0038_linear_large', 'experiment_id': 'linear_q2_evaluation', 'experiment_iteration': 6, 'target_workload': {'id': 'application_1753554264659_0011_linear_large', 'execution_time': 2976, 'name': 'linear', 'input_data_size': 'large', 'configuration': {'driver_cores': 2, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 4, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 250, 'task_cpus': 1}}, 'objective_function_real': 5280.000000000004, 'acquisition_function_score': 1934.32, 'resource_usage_value': 7.0, 'execution_time': 5280, 'configuration': {'driver_cores': 1, 'driver_memory': 2, 'executor_cores': 1, 'executor_instances': 1, 'executor_memory': 5, 'sql_shuffle_partitions': 300, 'task_cpus': 1}, 'execution_time_error': 3346, 'objective_function_predict': 1934.3200000000006, 'beta': None, 'alpha': None, 'repeated_config': None, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1758867966614_0038_linear_large documents into MongoDB

======================================================================================================================================================
[YORO/SBO] Evaluated (success #6):
    T_real=5280.00 | T_pred=1934.32 | OF_real=5280.00
    cfg=[  1   2   1   1   5 300   1]
======================================================================================================================================================

[YORO/SBO] Iter 7: T_pred=1934.80 | cfg=[  1   3   1   3   4 200   1]
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: yoro_bo_baseline, config: driver_cores=1 driver_memory=3 executor_cores=1 executor_instances=3 executor_memory=4 sql_shuffle_partitions=200 task_cpus=1
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/linear/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/linear/spark/run.sh
patching args=
start LinearRegression bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.LinearRegressionWithElasticNet           --master yarn --num-executors 3 --executor-cores 1 --executor-memory 4g --driver-memory 3g --driver-cores 1 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --regParam 0.3 --elasticNetParam 0.8 --maxIter 50 --tol 1E-6 hdfs://172.30.0.20:9000/HiBench/Linear/Input/large
25/09/27 20:46:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/09/27 20:46:30 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/09/27 20:46:31 INFO Configuration: resource-types.xml not found
25/09/27 20:46:31 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/09/27 20:46:31 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/09/27 20:46:31 INFO Client: Will allocate AM container, with 3456 MB memory including 384 MB overhead
25/09/27 20:46:31 INFO Client: Setting up container launch context for our AM
25/09/27 20:46:31 INFO Client: Setting up the launch environment for our AM container
25/09/27 20:46:31 INFO Client: Preparing resources for our AM container
25/09/27 20:46:31 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/09/27 20:46:32 INFO Client: Uploading resource file:/tmp/spark-ff16d8fe-3fbe-47b4-b5c5-91a95d8ac82e/__spark_libs__6277223582778585365.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0039/__spark_libs__6277223582778585365.zip
25/09/27 20:46:33 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0039/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/09/27 20:46:35 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0039/sparkbench.conf
25/09/27 20:46:35 INFO Client: Uploading resource file:/tmp/spark-ff16d8fe-3fbe-47b4-b5c5-91a95d8ac82e/__spark_conf__1955449578648893079.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0039/__spark_conf__.zip
25/09/27 20:46:36 INFO SecurityManager: Changing view acls to: sparker
25/09/27 20:46:36 INFO SecurityManager: Changing modify acls to: sparker
25/09/27 20:46:36 INFO SecurityManager: Changing view acls groups to:
25/09/27 20:46:36 INFO SecurityManager: Changing modify acls groups to:
25/09/27 20:46:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/09/27 20:46:36 INFO Client: Submitting application application_1758867966614_0039 to ResourceManager
25/09/27 20:46:36 INFO YarnClientImpl: Submitted application application_1758867966614_0039

=================================================================
Detected application_1758867966614_0039
=================================================================

25/09/27 20:46:37 INFO Client: Application report for application_1758867966614_0039 (state: ACCEPTED)
25/09/27 20:46:37 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1759005996203
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0039/
	 user: sparker
25/09/27 20:46:38 INFO Client: Application report for application_1758867966614_0039 (state: ACCEPTED)
25/09/27 20:46:39 INFO Client: Application report for application_1758867966614_0039 (state: ACCEPTED)
25/09/27 20:46:40 INFO Client: Application report for application_1758867966614_0039 (state: ACCEPTED)
25/09/27 20:46:41 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-3
	 ApplicationMaster RPC port: 44581
	 queue: default
	 start time: 1759005996203
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0039/
	 user: sparker
25/09/27 21:37:19 INFO Client: Application report for application_1758867966614_0039 (state: FINISHED)
25/09/27 21:37:20 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-3
	 ApplicationMaster RPC port: 44581
	 queue: default
	 start time: 1759005996203
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0039/
	 user: sparker
25/09/27 21:37:20 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1758867966614_0039 with large data and queued
=================================================================

25/09/27 21:37:20 INFO ShutdownHookManager: Deleting directory /tmp/spark-151fd86a-daa1-4b8c-8226-782fbe04fefd
25/09/27 21:37:20 INFO ShutdownHookManager: Deleting directory /tmp/spark-ff16d8fe-3fbe-47b4-b5c5-91a95d8ac82e
/home/sparker/shared/HiBench2/bin/workloads/ml/linear/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1758867966614_0039
Failed to download Spark logs, we'll retry in next iteration 1: 500 Server Error: Server Error for url: http://localhost:18080/api/v1/applications/application_1758867966614_0039/logs
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1758867966614_0039.zip
====================================================================================================
Benchmark Name: linear
Time to create app instrumentation: 0.06 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.08 seconds
Time to create stages instrumentation: 0.51 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 40.81 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
46.458512
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
46.713319
====================================================================================================
SQL PLANS: 4 | JOBS: 102 | JOBS WITHOUT SQL PLAN: 98 | STAGES: 201 | STAGES SKIPPED: 98 | TASK: 61756 TASK_WITH_ERRORS: 0 |
********************** Not in SqlPlanNodeNameType************
WholeStageCodegen (2)
********************************************************************
********************** Not in SqlPlanNodeNameType************
WholeStageCodegen (1)
********************************************************************
Get distributions elapsed_time: 0.077659 seconds
Starting parallel processing.
Time taken for parallel processing: 0.08927750587463379 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
46.756009
====================================================================================================
Finished application vectorization for application_1758867966614_0039_linear_large
Saving optimized workload into MongoDB: {'_id': 'application_1758867966614_0039_linear_large', 'experiment_id': 'linear_q2_evaluation', 'experiment_iteration': 7, 'target_workload': {'id': 'application_1753554264659_0011_linear_large', 'execution_time': 2976, 'name': 'linear', 'input_data_size': 'large', 'configuration': {'driver_cores': 2, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 4, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 250, 'task_cpus': 1}}, 'objective_function_real': 3038.9999999999986, 'acquisition_function_score': 1934.8, 'resource_usage_value': 15.0, 'execution_time': 3039, 'configuration': {'driver_cores': 1, 'driver_memory': 3, 'executor_cores': 1, 'executor_instances': 3, 'executor_memory': 4, 'sql_shuffle_partitions': 200, 'task_cpus': 1}, 'execution_time_error': 1105, 'objective_function_predict': 1934.7999999999995, 'beta': None, 'alpha': None, 'repeated_config': None, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1758867966614_0039_linear_large documents into MongoDB

======================================================================================================================================================
[YORO/SBO] Evaluated (success #7):
    T_real=3039.00 | T_pred=1934.80 | OF_real=3039.00
    cfg=[  1   3   1   3   4 200   1]
======================================================================================================================================================

[YORO/SBO] Iter 8: T_pred=1951.14 | cfg=[  3   4   5   2   5 300   1]
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: yoro_bo_baseline, config: driver_cores=3 driver_memory=4 executor_cores=5 executor_instances=2 executor_memory=5 sql_shuffle_partitions=300 task_cpus=1
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/linear/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/linear/spark/run.sh
patching args=
start LinearRegression bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.LinearRegressionWithElasticNet           --master yarn --num-executors 2 --executor-cores 5 --executor-memory 5g --driver-memory 4g --driver-cores 3 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --regParam 0.3 --elasticNetParam 0.8 --maxIter 50 --tol 1E-6 hdfs://172.30.0.20:9000/HiBench/Linear/Input/large
25/09/27 21:38:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/09/27 21:38:44 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/09/27 21:38:45 INFO Configuration: resource-types.xml not found
25/09/27 21:38:45 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/09/27 21:38:45 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/09/27 21:38:45 INFO Client: Will allocate AM container, with 4505 MB memory including 409 MB overhead
25/09/27 21:38:45 INFO Client: Setting up container launch context for our AM
25/09/27 21:38:45 INFO Client: Setting up the launch environment for our AM container
25/09/27 21:38:45 INFO Client: Preparing resources for our AM container
25/09/27 21:38:45 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/09/27 21:38:46 INFO Client: Uploading resource file:/tmp/spark-1f5d3209-dd86-4d05-90e4-1bd2480e308a/__spark_libs__5548699301554257190.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0040/__spark_libs__5548699301554257190.zip
25/09/27 21:38:47 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0040/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/09/27 21:38:49 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0040/sparkbench.conf
25/09/27 21:38:49 INFO Client: Uploading resource file:/tmp/spark-1f5d3209-dd86-4d05-90e4-1bd2480e308a/__spark_conf__3519292331956697387.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0040/__spark_conf__.zip
25/09/27 21:38:50 INFO SecurityManager: Changing view acls to: sparker
25/09/27 21:38:50 INFO SecurityManager: Changing modify acls to: sparker
25/09/27 21:38:50 INFO SecurityManager: Changing view acls groups to:
25/09/27 21:38:50 INFO SecurityManager: Changing modify acls groups to:
25/09/27 21:38:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/09/27 21:38:50 INFO Client: Submitting application application_1758867966614_0040 to ResourceManager
25/09/27 21:38:50 INFO YarnClientImpl: Submitted application application_1758867966614_0040

=================================================================
Detected application_1758867966614_0040
=================================================================

25/09/27 21:38:51 INFO Client: Application report for application_1758867966614_0040 (state: ACCEPTED)
25/09/27 21:38:51 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1759009130297
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0040/
	 user: sparker
25/09/27 21:38:52 INFO Client: Application report for application_1758867966614_0040 (state: ACCEPTED)
25/09/27 21:38:53 INFO Client: Application report for application_1758867966614_0040 (state: ACCEPTED)
25/09/27 21:38:54 INFO Client: Application report for application_1758867966614_0040 (state: ACCEPTED)
25/09/27 21:38:55 INFO Client: Application report for application_1758867966614_0040 (state: ACCEPTED)
25/09/27 21:38:56 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-3
	 ApplicationMaster RPC port: 41487
	 queue: default
	 start time: 1759009130297
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0040/
	 user: sparker
25/09/27 22:22:08 INFO Client: Application report for application_1758867966614_0040 (state: FINISHED)
25/09/27 22:22:08 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-3
	 ApplicationMaster RPC port: 41487
	 queue: default
	 start time: 1759009130297
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0040/
	 user: sparker
25/09/27 22:22:08 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1758867966614_0040 with large data and queued
=================================================================

25/09/27 22:22:08 INFO ShutdownHookManager: Deleting directory /tmp/spark-2c73d9de-7b1f-4aca-84cf-9e25aa742f46
25/09/27 22:22:08 INFO ShutdownHookManager: Deleting directory /tmp/spark-1f5d3209-dd86-4d05-90e4-1bd2480e308a
/home/sparker/shared/HiBench2/bin/workloads/ml/linear/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1758867966614_0040
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1758867966614_0040.zip
====================================================================================================
Benchmark Name: linear
Time to create app instrumentation: 0.06 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.08 seconds
Time to create stages instrumentation: 0.49 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 42.75 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
49.344681
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
49.614268
====================================================================================================
SQL PLANS: 4 | JOBS: 102 | JOBS WITHOUT SQL PLAN: 98 | STAGES: 201 | STAGES SKIPPED: 98 | TASK: 61756 TASK_WITH_ERRORS: 0 |
********************** Not in SqlPlanNodeNameType************
WholeStageCodegen (2)
********************************************************************
********************** Not in SqlPlanNodeNameType************
WholeStageCodegen (1)
********************************************************************
Get distributions elapsed_time: 0.108129 seconds
Starting parallel processing.
Time taken for parallel processing: 0.0979621410369873 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
49.700848
====================================================================================================
Finished application vectorization for application_1758867966614_0040_linear_large
Saving optimized workload into MongoDB: {'_id': 'application_1758867966614_0040_linear_large', 'experiment_id': 'linear_q2_evaluation', 'experiment_iteration': 8, 'target_workload': {'id': 'application_1753554264659_0011_linear_large', 'execution_time': 2976, 'name': 'linear', 'input_data_size': 'large', 'configuration': {'driver_cores': 2, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 4, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 250, 'task_cpus': 1}}, 'objective_function_real': 2593.0000000000005, 'acquisition_function_score': 1951.14, 'resource_usage_value': 62.0, 'execution_time': 2593, 'configuration': {'driver_cores': 3, 'driver_memory': 4, 'executor_cores': 5, 'executor_instances': 2, 'executor_memory': 5, 'sql_shuffle_partitions': 300, 'task_cpus': 1}, 'execution_time_error': 642, 'objective_function_predict': 1951.1399999999996, 'beta': None, 'alpha': None, 'repeated_config': None, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1758867966614_0040_linear_large documents into MongoDB

======================================================================================================================================================
[YORO/SBO] Evaluated (success #8):
    T_real=2593.00 | T_pred=1951.14 | OF_real=2593.00
    cfg=[  3   4   5   2   5 300   1]
======================================================================================================================================================

[YORO/SBO] Iter 9: T_pred=2332.80 | cfg=[  2   3   4   3   3 250   2]
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: yoro_bo_baseline, config: driver_cores=2 driver_memory=3 executor_cores=4 executor_instances=3 executor_memory=3 sql_shuffle_partitions=250 task_cpus=2
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/linear/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/linear/spark/run.sh
patching args=
start LinearRegression bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.LinearRegressionWithElasticNet           --master yarn --num-executors 3 --executor-cores 4 --executor-memory 3g --driver-memory 3g --driver-cores 2 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --regParam 0.3 --elasticNetParam 0.8 --maxIter 50 --tol 1E-6 hdfs://172.30.0.20:9000/HiBench/Linear/Input/large
25/09/27 22:23:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/09/27 22:23:16 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/09/27 22:23:17 INFO Configuration: resource-types.xml not found
25/09/27 22:23:17 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/09/27 22:23:17 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/09/27 22:23:17 INFO Client: Will allocate AM container, with 3456 MB memory including 384 MB overhead
25/09/27 22:23:17 INFO Client: Setting up container launch context for our AM
25/09/27 22:23:17 INFO Client: Setting up the launch environment for our AM container
25/09/27 22:23:17 INFO Client: Preparing resources for our AM container
25/09/27 22:23:17 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/09/27 22:23:18 INFO Client: Uploading resource file:/tmp/spark-425199df-c95d-4a46-809f-a1bb703dc902/__spark_libs__4874994567072466112.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0041/__spark_libs__4874994567072466112.zip
25/09/27 22:23:20 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0041/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/09/27 22:23:23 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0041/sparkbench.conf
25/09/27 22:23:24 INFO Client: Uploading resource file:/tmp/spark-425199df-c95d-4a46-809f-a1bb703dc902/__spark_conf__5657836300442992839.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0041/__spark_conf__.zip
25/09/27 22:23:24 INFO SecurityManager: Changing view acls to: sparker
25/09/27 22:23:24 INFO SecurityManager: Changing modify acls to: sparker
25/09/27 22:23:24 INFO SecurityManager: Changing view acls groups to:
25/09/27 22:23:24 INFO SecurityManager: Changing modify acls groups to:
25/09/27 22:23:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/09/27 22:23:24 INFO Client: Submitting application application_1758867966614_0041 to ResourceManager
25/09/27 22:23:24 INFO YarnClientImpl: Submitted application application_1758867966614_0041

=================================================================
Detected application_1758867966614_0041
=================================================================

25/09/27 22:23:25 INFO Client: Application report for application_1758867966614_0041 (state: ACCEPTED)
25/09/27 22:23:25 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1759011804279
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0041/
	 user: sparker
25/09/27 22:23:26 INFO Client: Application report for application_1758867966614_0041 (state: ACCEPTED)
25/09/27 22:23:27 INFO Client: Application report for application_1758867966614_0041 (state: ACCEPTED)
25/09/27 22:23:28 INFO Client: Application report for application_1758867966614_0041 (state: ACCEPTED)
25/09/27 22:23:29 INFO Client: Application report for application_1758867966614_0041 (state: ACCEPTED)
25/09/27 22:23:30 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-1
	 ApplicationMaster RPC port: 42515
	 queue: default
	 start time: 1759011804279
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0041/
	 user: sparker
25/09/27 23:11:10 INFO Client: Application report for application_1758867966614_0041 (state: FINISHED)
25/09/27 23:11:10 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-1
	 ApplicationMaster RPC port: 42515
	 queue: default
	 start time: 1759011804279
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0041/
	 user: sparker
25/09/27 23:11:10 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1758867966614_0041 with large data and queued
=================================================================

25/09/27 23:11:10 INFO ShutdownHookManager: Deleting directory /tmp/spark-a790d88b-1140-496d-8c59-987746d9a801
25/09/27 23:11:10 INFO ShutdownHookManager: Deleting directory /tmp/spark-425199df-c95d-4a46-809f-a1bb703dc902
/home/sparker/shared/HiBench2/bin/workloads/ml/linear/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1758867966614_0041
Failed to download Spark logs, we'll retry in next iteration 1: 500 Server Error: Server Error for url: http://localhost:18080/api/v1/applications/application_1758867966614_0041/logs
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1758867966614_0041.zip
====================================================================================================
Benchmark Name: linear
Time to create app instrumentation: 0.06 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.07 seconds
Time to create stages instrumentation: 0.48 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 41.59 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
47.541767
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
47.807741
====================================================================================================
SQL PLANS: 4 | JOBS: 102 | JOBS WITHOUT SQL PLAN: 98 | STAGES: 201 | STAGES SKIPPED: 98 | TASK: 61756 TASK_WITH_ERRORS: 0 |
********************** Not in SqlPlanNodeNameType************
WholeStageCodegen (2)
********************************************************************
********************** Not in SqlPlanNodeNameType************
WholeStageCodegen (1)
********************************************************************
Get distributions elapsed_time: 0.076373 seconds
Starting parallel processing.
Time taken for parallel processing: 0.0908973217010498 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
47.865119
====================================================================================================
Finished application vectorization for application_1758867966614_0041_linear_large
Saving optimized workload into MongoDB: {'_id': 'application_1758867966614_0041_linear_large', 'experiment_id': 'linear_q2_evaluation', 'experiment_iteration': 9, 'target_workload': {'id': 'application_1753554264659_0011_linear_large', 'execution_time': 2976, 'name': 'linear', 'input_data_size': 'large', 'configuration': {'driver_cores': 2, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 4, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 250, 'task_cpus': 1}}, 'objective_function_real': 2859.999999999999, 'acquisition_function_score': 2332.8, 'resource_usage_value': 42.0, 'execution_time': 2860, 'configuration': {'driver_cores': 2, 'driver_memory': 3, 'executor_cores': 4, 'executor_instances': 3, 'executor_memory': 3, 'sql_shuffle_partitions': 250, 'task_cpus': 2}, 'execution_time_error': 528, 'objective_function_predict': 2332.8000000000006, 'beta': None, 'alpha': None, 'repeated_config': None, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1758867966614_0041_linear_large documents into MongoDB

======================================================================================================================================================
[YORO/SBO] Evaluated (success #9):
    T_real=2860.00 | T_pred=2332.80 | OF_real=2860.00
    cfg=[  2   3   4   3   3 250   2]
======================================================================================================================================================

[YORO/SBO] Iter 10: T_pred=2343.38 | cfg=[  1   2   2   2   5 100   2]
base_path_hibench='D:\\Spark\\hadoop-spark-cluster\\shared-master\\HiBench2' spark_history_server_url='http://localhost:18080/api/v1/applications/'
hostname='spark-cluster-master' port=2222 username='sparker' password='sparker' command='cd /home/sparker/shared/HiBench2 && ./bin/run_all.sh --skip-if-exists'
Running HiBench Spark job with data scale: large, framework: yoro_bo_baseline, config: driver_cores=1 driver_memory=2 executor_cores=2 executor_instances=2 executor_memory=5 sql_shuffle_partitions=100 task_cpus=2
./bin
/home/sparker/shared/HiBench2
*** Skipping data preparation for workloads ***
Run ml/linear/spark
Exec script: /home/sparker/shared/HiBench2/bin/workloads/ml/linear/spark/run.sh
patching args=
start LinearRegression bench
Export env: SPARKBENCH_PROPERTIES_FILES=/home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/home/sparker/hadoop-3.3.2/etc/hadoop
Submit Spark job: /home/sparker/spark-3.3.2-bin-hadoop3/bin/spark-submit            --files /home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf           --properties-file /home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/spark.conf           --conf spark.executorEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --conf spark.yarn.appMasterEnv.SPARKBENCH_PROPERTIES_FILES=sparkbench.conf           --class com.intel.hibench.sparkbench.ml.LinearRegressionWithElasticNet           --master yarn --num-executors 2 --executor-cores 2 --executor-memory 5g --driver-memory 2g --driver-cores 1 --deploy-mode cluster /home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar --regParam 0.3 --elasticNetParam 0.8 --maxIter 50 --tol 1E-6 hdfs://172.30.0.20:9000/HiBench/Linear/Input/large
25/09/27 23:12:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/09/27 23:12:36 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at spark-cluster-master/172.30.0.20:8032
25/09/27 23:12:37 INFO Configuration: resource-types.xml not found
25/09/27 23:12:37 INFO ResourceUtils: Unable to find 'resource-types.xml'.
25/09/27 23:12:37 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (46080 MB per container)
25/09/27 23:12:37 INFO Client: Will allocate AM container, with 2432 MB memory including 384 MB overhead
25/09/27 23:12:37 INFO Client: Setting up container launch context for our AM
25/09/27 23:12:37 INFO Client: Setting up the launch environment for our AM container
25/09/27 23:12:37 INFO Client: Preparing resources for our AM container
25/09/27 23:12:37 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/09/27 23:12:38 INFO Client: Uploading resource file:/tmp/spark-f221308b-313e-49cb-b63e-f4964b4f2d0b/__spark_libs__7361180231507630779.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0042/__spark_libs__7361180231507630779.zip
25/09/27 23:12:39 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/sparkbench/assembly/target/sparkbench-assembly-8.0-SNAPSHOT-dist.jar -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0042/sparkbench-assembly-8.0-SNAPSHOT-dist.jar
25/09/27 23:12:41 INFO Client: Uploading resource file:/home/sparker/shared/HiBench2/report/linear/spark/conf/sparkbench/sparkbench.conf -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0042/sparkbench.conf
25/09/27 23:12:41 INFO Client: Uploading resource file:/tmp/spark-f221308b-313e-49cb-b63e-f4964b4f2d0b/__spark_conf__8521131289062645237.zip -> hdfs://spark-cluster-master:9000/user/sparker/.sparkStaging/application_1758867966614_0042/__spark_conf__.zip
25/09/27 23:12:41 INFO SecurityManager: Changing view acls to: sparker
25/09/27 23:12:41 INFO SecurityManager: Changing modify acls to: sparker
25/09/27 23:12:41 INFO SecurityManager: Changing view acls groups to:
25/09/27 23:12:41 INFO SecurityManager: Changing modify acls groups to:
25/09/27 23:12:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparker); groups with view permissions: Set(); users  with modify permissions: Set(sparker); groups with modify permissions: Set()
25/09/27 23:12:42 INFO Client: Submitting application application_1758867966614_0042 to ResourceManager
25/09/27 23:12:42 INFO YarnClientImpl: Submitted application application_1758867966614_0042

=================================================================
Detected application_1758867966614_0042
=================================================================

25/09/27 23:12:43 INFO Client: Application report for application_1758867966614_0042 (state: ACCEPTED)
25/09/27 23:12:43 INFO Client:
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1759014762095
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0042/
	 user: sparker
25/09/27 23:12:44 INFO Client: Application report for application_1758867966614_0042 (state: ACCEPTED)
25/09/27 23:12:45 INFO Client: Application report for application_1758867966614_0042 (state: ACCEPTED)
25/09/27 23:12:46 INFO Client: Application report for application_1758867966614_0042 (state: ACCEPTED)
25/09/27 23:12:47 INFO Client: Application report for application_1758867966614_0042 (state: ACCEPTED)
25/09/27 23:12:48 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-3
	 ApplicationMaster RPC port: 41739
	 queue: default
	 start time: 1759014762095
	 final status: UNDEFINED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0042/
	 user: sparker
25/09/28 00:25:25 INFO Client: Application report for application_1758867966614_0042 (state: FINISHED)
25/09/28 00:25:26 INFO Client:
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: spark-cluster-slave-3
	 ApplicationMaster RPC port: 41739
	 queue: default
	 start time: 1759014762095
	 final status: SUCCEEDED
	 tracking URL: http://spark-cluster-master:8088/proxy/application_1758867966614_0042/
	 user: sparker
25/09/28 00:25:26 INFO ShutdownHookManager: Shutdown hook called

=================================================================
Finished application_1758867966614_0042 with large data and queued
=================================================================

25/09/28 00:25:26 INFO ShutdownHookManager: Deleting directory /tmp/spark-c3f55ea2-bf1e-4cb0-a59a-d235dc106f34
25/09/28 00:25:26 INFO ShutdownHookManager: Deleting directory /tmp/spark-f221308b-313e-49cb-b63e-f4964b4f2d0b
/home/sparker/shared/HiBench2/bin/workloads/ml/linear/spark/run.sh
Run all done!
Characterizing workload for application ID: application_1758867966614_0042
Failed to download Spark logs, we'll retry in next iteration 1: 500 Server Error: Server Error for url: http://localhost:18080/api/v1/applications/application_1758867966614_0042/logs
====================================================================================================
Processing:
D:\Spark\hadoop-spark-cluster\shared-master\HiBench2\logs\application_1758867966614_0042.zip
====================================================================================================
Benchmark Name: linear
Time to create app instrumentation: 0.06 seconds
Time to create executors instrumentation: 0.00 seconds
Time to create sql plans instrumentation: 0.00 seconds
Time to create jobs instrumentation: 0.07 seconds
Time to create stages instrumentation: 0.51 seconds
Error for not correlation 0*********************
Time to create tasks instrumentation: 40.89 seconds
====================================================================================================
1) Elapsed time to create profile of the sparkeventlog
46.851334
====================================================================================================
INSERT 1 documents into MongoDB
====================================================================================================
2) Elapsed time to create statistic vectors
47.184928
====================================================================================================
SQL PLANS: 4 | JOBS: 102 | JOBS WITHOUT SQL PLAN: 98 | STAGES: 201 | STAGES SKIPPED: 98 | TASK: 61756 TASK_WITH_ERRORS: 0 |
********************** Not in SqlPlanNodeNameType************
WholeStageCodegen (2)
********************************************************************
********************** Not in SqlPlanNodeNameType************
WholeStageCodegen (1)
********************************************************************
Get distributions elapsed_time: 0.073355 seconds
Starting parallel processing.
Time taken for parallel processing: 0.08849644660949707 seconds
UPDATE (already exits) 1 documents into MongoDB
====================================================================================================
3) Elapsed time to create Workload characterization
47.178881
====================================================================================================
Finished application vectorization for application_1758867966614_0042_linear_large
Saving optimized workload into MongoDB: {'_id': 'application_1758867966614_0042_linear_large', 'experiment_id': 'linear_q2_evaluation', 'experiment_iteration': 10, 'target_workload': {'id': 'application_1753554264659_0011_linear_large', 'execution_time': 2976, 'name': 'linear', 'input_data_size': 'large', 'configuration': {'driver_cores': 2, 'driver_memory_gb': 2, 'dynamic_allocation': False, 'executor_cores': 4, 'executor_instances': 3, 'executor_memory_gb': 3, 'sql_adaptive': False, 'sql_shuffle_partitions': 250, 'task_cpus': 1}}, 'objective_function_real': 4358.0, 'acquisition_function_score': 2343.38, 'resource_usage_value': 22.0, 'execution_time': 4358, 'configuration': {'driver_cores': 1, 'driver_memory': 2, 'executor_cores': 2, 'executor_instances': 2, 'executor_memory': 5, 'sql_shuffle_partitions': 100, 'task_cpus': 2}, 'execution_time_error': 2015, 'objective_function_predict': 2343.3799999999997, 'beta': None, 'alpha': None, 'repeated_config': None, 'suboptimal': None, 'converged': None, 'safe_transfer_learning': None}
INSERT application_1758867966614_0042_linear_large documents into MongoDB

======================================================================================================================================================
[YORO/SBO] Evaluated (success #10):
    T_real=4358.00 | T_pred=2343.38 | OF_real=4358.00
    cfg=[  1   2   2   2   5 100   2]
======================================================================================================================================================


=== Metrics (10 iterations) — YORO/SBO ===
T best ↓   : 1635.00  (found at i=5)
T first ↓  : 1645.00
SU (%) ↑   : 45.06
TC ↓       : 29441.00
Hit@0.10 ↑ : 20.00
nAOCC ↓    : 0.8007


